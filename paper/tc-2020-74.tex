
\documentclass[tc, noline]{copernicus}

\begin{document}

\title{DeepBedMap: a deep neural network for resolving the bed topography of Antarctica}

\Author{Wei~Ji}{Leong}
\Author{Huw~Joseph}{Horgan}

\affil{Antarctic Research Centre, Victoria University of Wellington, Wellington, New Zealand}

\runningtitle{DeepBedMap Antarctica}

\runningauthor{W.~J.~Leong~and~H.~J.~Horgan}

\correspondence{Wei Ji Leong (weiji.leong@vuw.ac.nz) and Huw Joseph Horgan (huw.horgan@vuw.ac.nz)}

\received{18~March 2020}
\accepted{18~September 2020}
\revised{1~September 2020}
\pubdiscuss{16~April 2020}
\published{}

\firstpage{1}

\texlicencestatement{This work is distributed under \hack{\newline} the Creative Commons Attribution 4.0 License.}
\maketitle

\begin{abstract}
To resolve the bed elevation of Antarctica, we present DeepBedMap~-- a novel machine learning method that can produce Antarctic bed topography with
  adequate surface roughness from multiple remote sensing data inputs. The super-resolution deep convolutional neural network model is trained on
  scattered regions in Antarctica where high-resolution (250\,\unit{m}) ground-truth bed elevation grids are available. This model is then used to
  generate high-resolution bed topography in less surveyed areas. DeepBedMap improves on previous interpolation methods by not restricting itself to a
  low-spatial-resolution (1000\,\unit{m}) BEDMAP2 raster image as its prior image. It takes in additional high-spatial-resolution datasets, such as ice
  surface elevation, velocity and snow accumulation, to better inform the bed topography even in the absence of ice thickness data from direct
  ice-penetrating-radar surveys. The DeepBedMap model is based on an adapted architecture of the Enhanced Super-Resolution Generative Adversarial Network,
  chosen to minimize per-pixel elevation errors while producing realistic topography. The final product is a four-times-upsampled (250\,\unit{m}) bed
  elevation model of Antarctica that can be used by glaciologists interested in the subglacial terrain and by ice sheet modellers wanting to run
  catchment- or continent-scale ice sheet model simulations. We show that DeepBedMap offers a rougher topographic profile compared to the standard
  bicubically interpolated BEDMAP2 and BedMachine Antarctica and envision it being used where a high-resolution bed elevation model is required.
\end{abstract}

\hack{\newpage}

\introduction

The bed of the Antarctic ice sheet is one of the most challenging surfaces on Earth to map due to the thick layer of ice cover. Knowledge of bed
elevation is however essential for estimating the volume of ice currently stored in the ice sheets and for input to the numerical models that are
used to estimate the contribution ice sheets are likely to make to sea level in the coming century. The Antarctic ice sheet is estimated to hold a
sea level equivalent (SLE) of 57.9\,$\pm$\,0.9\,\unit{m} \citep{MorlighemDeepglacialtroughs2019}. Between 2012 and 2017, the Antarctic ice sheet was
losing mass at an average rate of 219\,$\pm$\,43\,\unit{Gt\,yr^{-1}} (0.61\,$\pm$\,0.12\,\unit{mm\,yr^{-1}} SLE), with most of the ice loss attributed
to the acceleration, retreat and rapid thinning of major West Antarctic Ice Sheet outlet glaciers \citep{IMBIEMassbalanceAntarctic2018}. Bed elevation
exerts additional controls on ice flow by routing subglacial water and providing frictional resistance to flow
\citep{SiegertMacroscalebedroughness2004}. Bed roughness, especially at short wavelengths, exerts a frictional force against the flow of ice, making
it an important influence on ice velocity \citep{BinghamDiverselandscapesPine2017,FalciniQuantifyingbedroughness2018}. The importance of bed elevation
has led to major efforts to compile bed elevation models of Antarctica, notably with the BEDMAP1 \citep{LytheBEDMAPnewice2001} and BEDMAP2
\citep{FretwellBedmap2improvedice2013} products. A need for a higher-spatial-resolution digital elevation model (DEM) is also apparent, as ice sheet
models move to using sub-kilometre grids in order to quantify glacier ice flow dynamics more accurately
\citep{LeBrocqimprovedAntarcticdataset2010,Grahamhighresolutionsyntheticbed2017}. Finer grids are especially important at the ice sheet's grounding
zone on which adaptive mesh refinement schemes have focused \citep[e.g.][]{CornfordAdaptivemeshrefinement2016}, and attention to the bed roughness
component is imperative for proper modelling of fast-flowing outlet glaciers
\citep{DurandImpactbedrockdescription2011,NiasContrastingmodelledsensitivity2016}. Here we address the challenge of producing a high-resolution DEM
while preserving a realistic representation of the bed terrain's roughness.

Estimating bed elevation directly from geophysical observations primarily uses ice-penetrating-radar methods
\citep[e.g.][]{RobinRadioechoexploration1970}. Airborne radar methods enable reliable along-track estimates with low uncertainty (around the 1\,{\%}
level) introduced by imperfect knowledge of the firn and ice velocity structure, with some potential uncertainty introduced by picking the bed
return. Radar-derived bed estimates remain limited in their geographic coverage \citep{FretwellBedmap2improvedice2013} and are typically anisotropic
in their coverage, with higher spatial sampling in the along-track direction than between tracks.

To overcome these limitations, indirect methods of estimating bed elevation have been developed, and these include inverse methods and spatial
statistical methods. Inverse methods use surface observations combined with glaciological-process knowledge to determine ice thickness
\citep[e.g.][]{vanPeltiterativeinversemethod2013}. A non-linear relationship exists between the thickness of glaciers, ice streams and ice sheets and
how they flow \citep{Raymondrelationshipsurfacebasal2005}, meaning one can theoretically use a well-resolved surface to infer bed properties
\citep[e.g.][]{Farinottimethodestimateice2009}. Using surface observation inputs, such as the glacier outline, surface digital elevation models,
surface mass balance, surface rate of elevation change, and surface ice flow velocity, various models have been tested in the Ice Thickness Models
Intercomparison eXperiment \citep[ITMIX;][]{FarinottiHowaccurateare2017} to determine ice thickness (surface elevation minus bed elevation). While
significant inter-model uncertainties do exist, they can be mitigated by combining several models in an ensemble to provide a better consensus
estimate \citep{Farinotticonsensusestimateice2019}. On a larger scale, the inverse technique has also been applied to the Greenland
\citep{MorlighemBedMachinev3Complete2017} and Antarctic \citep{MorlighemDeepglacialtroughs2019} ice sheets, specifically using the mass conservation
approach \citep{Morlighemmassconservationapproach2011}. Spatial statistical methods seek to derive a higher-spatial-resolution bed by applying the
topographical likeness of bed features known to great detail in one area to other regions. For example, the conditional simulation method applied by
\citet{GoffConditionalsimulationThwaites2014} is able to resolve both fine-scale roughness and channelized morphology over the complex topography of
Thwaites Glacier and make use of the fact that roughness statistics are different between highland and lowland
areas. \citet{Grahamhighresolutionsyntheticbed2017} uses a two-step approach to generate their synthetic high-resolution grid, with the high-frequency roughness
component coming from the ICECAP and BEDMAP1 compilation radar point data and the low-frequency component coming from BEDMAP2. Neither method is
perfect, and we see all of the above methods as complementary.

We present a deep-neural-network method that is trained on direct ice-penetrating-radar observations over Antarctica and one which has features from
both the indirect inverse modelling and spatial statistical methodologies. An artificial neural network, loosely based on biological neural networks,
is a system made up of neurons. Each neuron comprises a simple mathematical function that takes an input to produce an output value, and neural
networks work by combining many of these neurons together. The term deep neural network is used when there is not a direct function mapping between
the input data and final output but two or more layers that are connected to one another \citep[see][for a review]{LeCunDeeplearning2015}. They are
trained using backpropagation, a procedure whereby the weights or parameters of the neurons' connections are adjusted so as to minimize the error
between the ground truth and output of the neural network \citep{RumelhartLearningrepresentationsbackpropagating1986}. Similar work has been done
before using artificial neural networks for estimating bed topography
\citep[e.g.][]{ClarkeNeuralNetworksApplied2009,MonnierInferencebedtopography2018}, but to our knowledge, no-one so far in the glaciological community
has attempted to use convolutional neural networks that work in a more spatially aware, 2-dimensional setting. Convolutional neural networks differ
from standard artificial neural networks in that they use kernels or filters in place of regular neurons \citep[again, see][for a
review]{LeCunDeeplearning2015}. The techniques we employ are prevalent in the computer vision community, having existed since the 1980s
\citep{FukushimaNeocognitronnewalgorithm1982,LeCunBackpropagationAppliedHandwritten1989} and are commonly used in visual pattern recognition tasks
\citep[e.g.][]{LecunGradientbasedlearningapplied1998,KrizhevskyImageNetClassificationDeep2012}. Our main contributions are twofold: we (1)~present a high-resolution (250\,\unit{m}) bed elevation map of Antarctica that goes beyond the 1\,\unit{km} resolution of BEDMAP2
\citep{FretwellBedmap2improvedice2013} and (2)~design a deep convolutional neural network to integrate as many remote sensing datasets as possible
which are relevant to estimating Antarctica's bed topography. We name the neural network ``DeepBedMap'', and the resulting digital elevation model
(DEM) product ``DeepBedMap\_DEM''.


\section{Related work}

\subsection{Super resolution}\label{section:superresolution}

Super resolution involves the processing of a low-resolution raster image into a higher-resolution one \citep{TsaiMultiframeimagerestoration1984}. The
idea is similar to the work on enhancing regular photographs to look crisper. The problem is especially ill-posed because a specific low-resolution
input can correspond to many possible high-resolution outputs, resulting in the development of several different algorithms aimed at solving this
challenge \citep[see][for a review]{NasrollahiSuperresolutioncomprehensivesurvey2014}. One promising approach is to use deep neural networks
\citep{LeCunDeeplearning2015} to learn an end-to-end mapping between the low- and high-resolution images, a method coined the Super-Resolution
Convolutional Neural Network \citep[SRCNN;][]{DongImageSuperResolutionUsing2014}. Since the development of SRCNN, multiple advances have been made to
improve the perceptual quality of super-resolution neural networks \citep[see][for a review]{YangDeepLearningSingle2019}. One way is to use a better
loss function, also known as a cost function. A loss function is a mathematical function that represents the error between the output of the neural
network and the ground truth (see also Appendix~\ref{appendix:A}). By having an adversarial component in its loss function, the Super-Resolution
Generative Adversarial Network \citep[SRGAN;][]{LedigPhotoRealisticSingleImage2017} manages to produce super-resolution images with finer perceptual
details. A generative adversarial network \citep{GoodfellowGenerativeAdversarialNetworks2014} consists of two neural networks, a generator and a
discriminator. A common analogy used is to treat the generator as an artist that produces imitation paintings and the discriminator as an art critic
that determines the authenticity of the paintings. The artist wants to fool the critic into believing its paintings are real, while the critic tries
to identify problems with the painting. Over time, the artist or generator model learns to improve itself based on the critic's judgement, producing
authentic-looking paintings with high perceptual quality. Perceptual quality is the extent to which an image looks like a valid natural image, usually
as judged by a human. In this case, perceptual quality is quantified mathematically by the discriminator or critic taking into account high-level
features of an image like contrast, texture, etc. Another way to improve performance is by reconfiguring the neural network's architecture, wherein
the layout or building blocks of the neural network are changed. By removing unnecessary model components and adding residual connections
\citep{HeDeepResidualLearning2015}, an enhanced deep super-resolution network \citep[EDSR;][]{LimEnhancedDeepResidual2017} features a deeper neural
network model that has better performance than older models. For the DeepBedMap model, we choose to adapt the Enhanced Super-Resolution Generative
Adversarial Network \citep[ESRGAN;][]{WangESRGANEnhancedSuperResolution2019} which brings together the ideas mentioned above. This approach produces
state-of-the-art perceptual quality and won the 2018 Perceptual Image Restoration and Manipulation Challenge on Super Resolution (Third Region; \citealp{Blau2018PIRMChallenge2018}).


\subsection{Network conditioning}\label{section:networkconditioning}

Network conditioning means having a neural network process one source of information in the context of other sources
\citep{DumoulinFeaturewisetransformations2018}. In a geographic context, conditioning is akin to using not just one layer but also other relevant
layers with meaningful links to provide additional information for the task at hand. Many ways exist to insert extra conditional information into a
neural network, such as concatenation-based conditioning, conditional biasing, conditional scaling and conditional affine transformations
\citep{DumoulinFeaturewisetransformations2018}. We choose to use the concatenation-based conditioning approach, whereby all of the individual raster
images are concatenated together channel-wise, much like the individual bands of a multispectral satellite image. This was deemed the most appropriate
conditioning method as all the contextual remote sensing datasets are raster grid images and also because this approach aligns with related work in
the remote sensing field.

An example similar to this DEM super-resolution problem is the classic problem of pan-sharpening, whereby a blurry low-resolution multispectral image
conditioned with a high-resolution panchromatic image can be turned into a high-resolution multispectral image. There is ongoing research into the use
of deep convolutional neural networks for pan-sharpening
\citep{MasiPansharpeningConvolutionalNeural2016,ScarpaTargetAdaptiveCNNBasedPansharpening2018}, sometimes with the incorporation of specific
domain knowledge \citep{YangPanNetDeepNetwork2017}, all of which show promising improvements over classical image processing methods. More recently,
generative adversarial networks \citep{GoodfellowGenerativeAdversarialNetworks2014} have been used in the conditional sense for general image-to-image
translation tasks \citep[e.g.][]{IsolaImagetoImageTranslationConditional2016,ParkSemanticImageSynthesis2019}, and also for producing more realistic
pan-sharpened satellite images \citep{LiuPSGANGenerativeAdversarial2018}. Our DeepBedMap model builds upon these ideas and other related DEM
super-resolution work \citep{XuNonlocalsimilaritybased2015,ChenConvolutionalNeuralNetwork2016}, while incorporating extra conditional information
specific to the cryospheric domain for resolving the bed elevation of Antarctica.


\section{Data and methods}

\subsection{Data preparation} \label{section:datapreparation}

Our convolutional neural network model works on 2-D images, so we ensure all the datasets are in a suitable raster grid format. Ground-truth bed
elevation points picked from radar surveys (see Table~\ref{table:groundtruthdata}) are first compiled together onto a common Antarctic stereographic
projection (EPSG:3031) using the WGS84 datum, reprojecting where necessary. These points are then gridded onto a 250\,\unit{m} spatial resolution
(pixel-node-registered) grid. We preprocess the points first using Generic Mapping Tools v6.0 \citep[GMT6;][]{WesselGenericMappingTools2019},
computing the median elevation for each pixel block in a regular grid. The preprocessed points are then run through an adjustable-tension continuous-curvature spline function with a tension factor set to 0.35 to produce a digital elevation model grid. This grid is further post-processed to mask out
pixels that are more than 3~\unit{pixels} (750\,\unit{m}) from the nearest ground-truth point.

%T1
\begin{table}[t]
\caption{High-resolution ground-truth datasets from ice-penetrating-radar surveys (collectively labelled as~$y$) used to train the DeepBedMap model. Training site locations can be seen in Fig.~\ref{fig:2}.}
\label{table:groundtruthdata}
\begin{tabular}{ll}
\tophline
Location                        & Citation                                         \\\middlehline
Pine Island Glacier             & \citet{BinghamDiverselandscapesPine2017}         \\
Wilkes Subglacial Basin         & \citet{JordanHypothesismegaoutburstflooding2010} \\
Carlson Inlet                   & \citet{KingIcestreamnot2011}                     \\
Rutford Ice Stream              & \citet{KingSubglaciallandformsRutford2016}       \\
Various locations in Antarctica & \citet{ShiMultichannelCoherentRadar2010}         \\
\bottomhline
\end{tabular}
\end{table}

%T2
\begin{table*}[t]
\caption{Remote sensing dataset inputs into the DeepBedMap neural network model.}
\label{table:datainputs}
\begin{tabular}{lllll}
\tophline
Symbol & Name                        & Variable                                           & Spatial resolution           & Citation                                         \\\middlehline
$x$    & BEDMAP2                     & bed elevation (\unit{m})                           & {~~~~~~~}1000\,\unit{m}               & \citet{FretwellBedmap2improvedice2013}           \\
$w^1$  & REMA                        & surface elevation (\unit{m})                       & {~~~~~~~~~}100\,\unit{m}$^{\mathrm{b}}$ & \citet{HowatReferenceElevationModel2018}         \\
$w^2$  & MEaSUREs Ice Velocity       & VX, VY (\unit{m\,yr^{-1}})$^{\mathrm{a}}$          & {~~~~~~~~~}500\,\unit{m}$^{\mathrm{c}}$ & \citet{MouginotContinentwideinterferometric2019} \\
$w^3$  & Antarctic snow accumulation & snow accumulation rate (\unit{kg\,m^{-2}\,yr^{-1}}) & {~~~~~~~}1000\,\unit{m}               & \citet{ArthernAntarcticsnowaccumulation2006}     \\
\bottomhline
\end{tabular}
\belowtable{$^{\mathrm{a}}$\,Note that the $x$ and $y$~components of velocity are used here instead of the norm. \\
$^{\mathrm{b}}$\,Gaps in 100\,\unit{m} mosaic filled in with bilinear resampled 200\,\unit{m} resolution REMA image. \\
$^{\mathrm{c}}$\,Originally 450\,\unit{m}; bilinear resampled to 500\,\unit{m}.}
\end{table*}

%F1
\begin{figure*}[t]
\includegraphics[width=170mm]{tc-2020-74-f01.png}
\caption{DeepBedMap generator model architecture composed of three modules. The input module processes each of the four inputs (BEDMAP2, \citealp{FretwellBedmap2improvedice2013}; REMA, \citealp{HowatReferenceElevationModel2019}; MEaSUREs Ice Velocity, \citealp{MouginotMEaSUREsPhaseMap2019}; snow accumulation, \citealp{ArthernAntarcticsnowaccumulation2006}; see also Table~\ref{table:datainputs}) into a consistent tensor. The core module processes the rich information contained within the concatenated inputs. The upsampling module scales the tensor up by 4 times and does some extra processing to produce the output DeepBedMap\_DEM.}
\label{fig:1}
\end{figure*}

To create the training dataset, we use a sliding window to obtain square tiles cropped from the high-resolution (250\,\unit{m}) ground-truth bed
elevation grids, with each tile required to be completely filled with data (i.e. no Not a Number -- NaN -- values). Besides these ground-truth bed elevation tiles, we
also obtain other tiled inputs (see Table~\ref{table:datainputs}) corresponding to the same spatial bounding box area. To reduce border edge artefacts
in the prediction, the neural network model's input convolutional layers (see Fig.~\ref{fig:1}) use no padding (also known as ``valid'' padding) when
performing the initial convolution operation. This means that the model input grids ($x$, $w^1$, $w^2$, $w^3$) have to cover a larger spatial area
than the ground-truth grids~($y$). More specifically, the model inputs cover an area of 11\,\unit{km}\,$\times$\,11\,\unit{km}
(e.g. 11~\unit{pixels}\,$\times$\,11~\unit{pixels} for BEDMAP2), while the ground-truth grids cover an area of 9\,\unit{km}\,$\times$\,9\,\unit{km}
(36~\unit{pixels}\,$\times$\,36~\unit{pixels}). As the pixels of the ground-truth grids may not align perfectly with those of the model's input grids,
we use bilinear interpolation to ensure that all the input grids cover the same spatial bounds as those of the reference ground-truth tiles. The general
locations of these training tiles are shown in orange in Fig.~\ref{fig:2}.


\subsection{Model design}\label{section:modeldesign}

Our DeepBedMap model is a generative adversarial network \citep{GoodfellowGenerativeAdversarialNetworks2014} composed of two convolutional neural
network models, a generator $G_\theta$ that produces the bed elevation prediction and a discriminator $D_\eta$ critic that will judge the quality of
this output. The two models are trained to compete against each other, with the generator trying to produce images that are misclassified as real by
the discriminator and the discriminator learning to spot problems with the generator's prediction in relation to the ground truth. Following this is a
mathematical definition of the neural network models and their architecture.

The objective of the main super-resolution generator model $G_\theta$ is to produce a high-resolution (250\,\unit{m}) grid of Antarctica's bed
elevation $\hat{y}$ given a low-resolution (1000\,\unit{m}) BEDMAP2 \citep{FretwellBedmap2improvedice2013} image~$x$. However, the information
contained in BEDMAP2 is insufficient for this regular super-resolution task, so we provide the neural network with more context through network
conditioning (see Sect.~\ref{section:networkconditioning}). Specifically, the model is conditioned at the input block stage with three raster grids
(see Table~\ref{table:datainputs}): (1)~ice surface elevation~$w^1$, (2)~ice surface velocity~$w^2$ and (3)~snow accumulation~$w^3$. This can be
formulated as follows:
\begin{equation}\label{eq:1}
\hat{y} = G_\theta(x, w^1, w^2, w^3),
\end{equation}
where $G_\theta$ is the generator (see Fig.~\ref{fig:1}) that produces high-resolution image candidates~$\hat{y}$. For brevity in the following
equations, we simplify Eq.~(\ref{eq:1}) to hide conditional inputs $w^1, w^2$ and  $w^3$, so that all input images are represented using~$x$. To train the
generative adversarial network, we update the parameters of the generator~$\theta$ and discriminator~$\eta$ as follows:
\begin{align}
&\hat{\theta} = \arg\min_{\theta} \frac{1}{N}\sum_{n=1}^{N}L_{\mathrm{G}}(\hat{y}_n, y_n), \label{eq:2}\\
&\hat{\eta} = \arg\min_{\eta} \frac{1}{N}\sum_{n=1}^{N}L_{\mathrm{D}}(\hat{y}_n, y_n), \label{eq:3}
\end{align}
where new estimates of the neural network parameters~$\hat{\theta}$ and~$\hat{\eta}$ are produced by minimizing the total loss functions $L_{\mathrm{G}}$ and
$L_{\mathrm{D}}$, respectively, for the generator~$G$ and discriminator~$D$ and $\hat{y}_n$ and $y_n$ are the set of predicted and ground-truth high-resolution
images over $N$~training samples. The generator network's loss~$L_{\mathrm{G}}$ is a custom perceptual loss function with four weighted components~-- content,
adversarial, topographic and structural loss. The discriminator network's loss~$L_{\mathrm{D}}$ is designed to maximize the likelihood that predicted images are
classified as fake~(0) and ground-truth images are classified as real~(1). Details of these loss functions are described in Appendix~\ref{appendix:A}.

Noting that the objective of the generator~$G$ is opposite to that of the discriminator~$D$, we formulate the adversarial min--max problem following
\citet{GoodfellowGenerativeAdversarialNetworks2014} as
\begin{equation}\label{eq:4}
\begin{split}
\min_{G}\,\max_{D} V(G,D) =&~\mathbb{E}_{y \sim P_{\text{data}}(y)}[\ln D(y)]\\&+ \mathbb{E}_{x \sim P_{G(x)}}[\ln(1-D(G(x)))],
\end{split}
\end{equation}
where for the discriminator~$D$, we maximize the expectation~$\mathbb{E}$ or the likelihood that the probability distribution of the discriminator's
output fits $D(y)=1$ when $y \sim P_{\text{data}}(y)$; i.e. we want the discriminator to classify the high-resolution image as real (1) when the
image~$y$ is in the distribution of the ground-truth images $P_{\text{data}}(y)$. For the generator~$G$, we minimize the likelihood that the
discriminator classifies the generator output $D(G(x))=0$ when $x \sim P_{G(x)}$; i.e. we do not want the discriminator to classify the super-resolution image as fake~(0) when the inputs~$x$ are in the distribution of generated images~$P_{G(x)}$. The overall goal of the entire network is to
make the distribution of generated images~$G(x)$ as similar as possible to the ground truth~$y$ through optimizing the value function~$V$.

%F2
\begin{figure*}[t]
\includegraphics[width=120mm]{tc-2020-74-f02.png}
\caption{DeepBedMap\_DEM over the entire Antarctic continent. Plotted on an Antarctic stereographic projection (EPSG:3031) with elevation referenced to the WGS84 datum. Grounding line is plotted as thin black line. Purple box shows Pine Island Glacier extent used in Fig.~\ref{fig:3}. Yellow box shows Thwaites Glacier extent used in Fig.~\ref{fig:5}. Orange areas show locations of training tiles (see Table~\ref{table:groundtruthdata}).}
\label{fig:2}
\end{figure*}

DeepBedMap's model architecture is adapted from the Enhanced Super-Resolution Generative Adversarial Network
\citep[ESRGAN;][]{WangESRGANEnhancedSuperResolution2019}. The generator model~$G$ (see Fig.~\ref{fig:1}) consists of an input, core and upsampling
module. The input module is made up of four sub-networks, each one composed of a convolutional neural network that processes the input image into a
consistent 9\,$\times$\,9 shaped tensor. Note that the MEaSUREs Ice Velocity \citep{MouginotMEaSUREsPhaseMap2019} input has two channels, one each for
the $x$ and $y$~velocity components. All the processed inputs are then concatenated together channel-wise before being fed into the core module. The
core module is based on the ESRGAN architecture with 12 residual-in-residual dense blocks \citep[see][for
details]{WangESRGANEnhancedSuperResolution2019}, saddled in between a pre-residual and post-residual convolutional layer. A skip connection runs from
the pre-residual layer's output to the post-residual layer's output before being fed into the upsampling module. This skip connection
\citep{HeIdentityMappingsDeep2016} helps with the neural network training process by allowing the model to also consider minimally processed
information from the input module, instead of solely relying on derived information from the residual-block layers when performing the upsampling. The
upsampling module is composed of two upsampling blocks, specifically a nearest-neighbour upsampling followed by a convolutional layer and leaky
rectified linear unit \citep[LeakyReLU;][]{MaasRectifiernonlinearitiesimprove2013} activation, which progressively scales the tensors by 2 times each time. Following this are two deformable convolutional layers \citep{DaiDeformableConvolutionalNetworks2017} which produce the final-output super-resolution DeepBedMap\_DEM. This generator model is trained to gradually improve its prediction by comparing the predicted output with ground-truth
images in the training regions (see Fig.~\ref{fig:2}), using the total loss function defined in Eq.~(\ref{eq:A9}).

The main differences between the DeepBedMap generator model and ESRGAN are the custom input block at the beginning and the deformable convolutional
layers at the end. The custom input block is designed to handle the prior low-resolution BEDMAP2 image and conditional inputs (see
Table~\ref{table:datainputs}). Deformable convolution was chosen in place of the standard convolution so as to enhance the model's predictive
capability by having it learn dense spatial transformations.

Besides the generator model, there is a separate adversarial discriminator model $D$ (not shown in the paper). Again, we follow ESRGAN's
\citep{WangESRGANEnhancedSuperResolution2019} lead by implementing the adversarial discriminator network in the style of the Visual Geometry Group
convolutional neural network model \citep[VGG;][]{SimonyanVeryDeepConvolutional2014}. The discriminator model consists of 10 blocks made up of a
convolutional, batch normalization \citep{IoffeBatchNormalizationAccelerating2015} and LeakyReLU \citep{MaasRectifiernonlinearitiesimprove2013} layer,
followed by two fully connected layers comprised of 100\,\unit{neurons} and 1\,\unit{neuron}, respectively. For numerical stability, we omit the final
fully connected layer's sigmoid activation function from the discriminator model's construction, integrating it instead into the binary cross-entropy
loss functions at Eqs.~(\ref{eq:A2}) and~(\ref{eq:A3}) using the log-sum-exp function. The output of this discriminator model is a value ranging
from~0 (fake) to~1 (real) that scores the generator model's output image. This score is used by both the discriminator and generator in the training
process and helps to push the predictions towards more realistic bed elevations. More details of the neural network training setup can be found in
Appendix~\ref{appendix:B}.


\section{Results}

\subsection{DeepBedMap\_DEM topography}\label{section:deepbedmapdemtopography}

Here we present the output digital elevation model (DEM) of the super-resolution DeepBedMap neural network model and compare it with bed topography
produced by other methods. The resulting DEM has a 250\,\unit{m} spatial resolution and therefore a four-times upsampled bed elevation grid product of
BEDMAP2 \citep{FretwellBedmap2improvedice2013}. In Fig.~\ref{fig:2}, we show that the full Antarctic-wide DeepBedMap\_DEM manages to capture general
topographical features across the whole continent. The model is only valid for grounded-ice regions, but we have produced predictions extending
outside of the grounding-zone area (including ice shelf cavities) using the same bed elevation, surface elevation, ice velocity and snow accumulation
inputs where such data are available up to the ice shelf front. We emphasize that the bed elevation under the ice shelves has not been super resolved
properly and is not intended for ice sheet modelling use. Users are encouraged to cut the DeepBedMap\_DEM using their preferred grounding line
\citep[e.g.][]{BindschadlerGettingAntarcticanew2011,RignotAntarcticgroundingline2011,MouginotMEaSURESAntarcticBoundaries2017} and replace the under-ice-shelf areas with another bathymetry grid product \citep[e.g.][]{GEBCOCompilationGroupGEBCO2020Grid2020}. The transition from the DeepBedMap\_DEM
to the bathymetry product across the grounding zone can then be smoothed using inverse distance weighting or an alternative interpolation method.

%F3
\begin{figure*}[t]
\includegraphics[width=130mm]{tc-2020-74-f03.png}
\caption{Comparison of interpolated bed elevation grid products over Pine Island Glacier (see extent in Fig.~\ref{fig:2}). \textbf{(a)}~DeepBedMap (ours) at 250\,\unit{m} resolution. \textbf{(b)}~BEDMAP2 \citep{FretwellBedmap2improvedice2013}, originally 1000\,\unit{m}, bicubically interpolated to 250\,\unit{m}. \textbf{(c)}~Elevation difference between DeepBedMap and BEDMAP2. \textbf{(d)}~BedMachine Antarctica \citep{MorlighemMEaSUREsBedMachineAntarctica2019}, originally 500\,\unit{m}, bicubically interpolated to 250\,\unit{m}.}
\label{fig:3}
\end{figure*}

%F4
\begin{figure*}[t]
\includegraphics[width=170mm]{tc-2020-74-f04.png}
\caption{Close-up views of DeepBedMap\_DEM around Antarctica. Panels \textbf{(a--c)}~show Siple Coast locations. Panels \textbf{(d--f)}~show Weddell Sea region locations. Panels \textbf{(g--i)}~show East Antarctica locations. Features of interest are annotated in black text against a white background: ridges~R, speckle patterns~S, terraces~T, wave patterns~W.}
\label{fig:4}
\end{figure*}

We now highlight some qualitative observations of DeepBedMap\_DEM's bed topography beneath Pine Island Glacier (Fig.~\ref{fig:3}) and other parts of
Antarctica (Fig.~\ref{fig:4}). DeepBedMap\_DEM shows a terrain with realistic topographical features, having fine-scale bumps and troughs that makes
it rougher than that of BEDMAP2 \citep{FretwellBedmap2improvedice2013} and BedMachine Antarctica \citep{MorlighemMEaSUREsBedMachineAntarctica2019}
while still preserving the general topography of the area (Fig.~\ref{fig:3}). Over steep topographical areas such as the Transantarctic Mountains
(Fig.~\ref{fig:4}a and~h), DeepBedMap produced speckle~(S) texture patterns. Along fast-flowing ice streams and glaciers
(Fig.~\ref{fig:4}b--h), we can see ridges~(R) aligned parallel to the sides of the valley, i.e. along the flow. In some cases, the ridges are
also oriented perpendicularly to the flow direction such as at Whillans Ice Stream (Fig.~\ref{fig:4}b), Bindschadler Ice Stream (Fig.~\ref{fig:4}c) and
Totten Glacier (Fig.~\ref{fig:4}g), resulting in intersecting ridges that create a box-like, honeycomb structure. Over relatively flat regions in
both West Antarctica and East Antarctica (e.g. Fig.~\ref{fig:4}g), there are some hummocky, wave-like~(W) patterns occasionally represented in the
terrain. Terrace~(T) features can occasionally be found winding along the side of hills such as at the Gamburtsev Subglacial Mountains
(Fig.~\ref{fig:4}i).


\subsection{Surface roughness} \label{section:surfaceroughness}

%F5
\begin{figure*}[t]
\includegraphics[width=130mm]{tc-2020-74-f05.png}
\caption{Spatial 2-D view of grids over Thwaites Glacier, West Antarctica. Plotted on an Antarctic stereographic projection (EPSG:3031) with elevation and SD values in metres referenced to the WGS84 datum. \textbf{(a)}~DeepBedMap digital elevation model. \textbf{(b)}~2-D roughness from the DeepBedMap\_DEM grid. \textbf{(c)}~2-D roughness from interpolated Operation IceBridge grid. \textbf{(d)}~2-D roughness from bicubically interpolated BedMachine Antarctica grid. Orange points in~\textbf{(a)} correspond to transect sampling locations used in Fig.~\ref{fig:6}.}
\label{fig:5}
\end{figure*}

We compare the roughness of DeepBedMap\_DEM vs. BedMachine Antarctica with ground-truth grids from processed Operation IceBridge data
\citep{ShiMultichannelCoherentRadar2010} using SD as a simple measure of roughness \citep{RippinBasalroughnessInstitute2014}. We calculate the surface
roughness for a single 250\,\unit{m} pixel from the SD of elevation values over a square 1250\,\unit{m}\,$\times$\,1250\,\unit{m} area
(i.e. 5~\unit{pixels}\,$\times$\,5~\unit{pixels}) surrounding the central pixel. Focusing on Thwaites Glacier, the spatial 2-D view of the
DeepBedMap\_DEM (Fig.~\ref{fig:5}a) shows a range of typical topographic features such as hills and canyons. The calculated 2-D roughnesses for both
DeepBedMap\_DEM (Fig.~\ref{fig:5}b) and the Ground truth (Fig.~\ref{fig:5}c) lie in a similar range from 0 to 400\,\unit{m}, whereas the roughness of
BedMachine Antarctica (Fig.~\ref{fig:5}d) is mostly in the 0-to-200\,\unit{m} range (hence the different colour scale). Also, the roughness pattern
for both DeepBedMap\_DEM and the ground truth has a more distributed cluster pattern made up of little pockets (especially towards the coastal region
on the left; see Fig.~\ref{fig:5}b and~c), whereas the BedMachine Antarctica roughness pattern shows larger cluster pockets in isolated regions (see
Fig.~\ref{fig:5}d).

Taking a 1-D transect over the 250\,\unit{m} resolution DeepBedMap\_DEM, BedMachine Antarctica and ground-truth grids, we illustrate the differences in
bed topography and roughness from the coast towards the inland area of Thwaites Glacier with a flight trace from Operation IceBridge (see
Fig.~\ref{fig:6}). For better comparison, we have calculated the Operation IceBridge ground-truth bed elevation and roughness values from a resampled
250\,\unit{m} grid instead of using its native along-track resolution. All three elevation profiles are shown to follow the same general trend from
the relatively rough coastal region (Fig.~\ref{fig:6}a from $-$1550 to $-$1500\,\unit{km} on the $x$~scale), along the retrograde slope (Fig.~\ref{fig:6}a
from $-$1500 to $-$1450\,\unit{km} on the $x$~scale) and into the interior region. DeepBedMap\_DEM features a relatively noisy elevation profile with
multiple fine-scale ($<$\,10\,\unit{km}) bumps and troughs similar to the ground truth, while BedMachine Antarctica shows a smoother profile that is
almost a moving average of the ground-truth elevation (Fig.~\ref{fig:6}a). Looking at the roughness statistic (Fig.~\ref{fig:6}b), both the
DeepBedMap\_DEM and Operation IceBridge ground-truth grids have a mean SD of about 40\,\unit{m}, whereas BedMachine Antarctica has a mean of about
10\,\unit{m} and rarely exceeds a SD value of 20\,\unit{m} along the transect.

%F6
\begin{figure}[t]
\includegraphics[width=83mm]{tc-2020-74-f06.png}
\caption{Comparing bed elevation~\textbf{(a)} and surface roughness~\textbf{(b)} (SD of elevation values) of each interpolated grid product (250\,\unit{m} resolution) over a transect (see Fig.~\ref{fig:5} for location of transect line). Purple values are from the super-resolution DeepBedMap\_DEM; orange values are from tension-spline-interpolated Operation IceBridge ground-truth points; green values are from bicubically interpolated BedMachine Antarctica. }
\label{fig:6}
\end{figure}


\section{Discussion}

\subsection{Bed features}

In Sect.~\ref{section:deepbedmapdemtopography}, we show that the DeepBedMap model has produced a high-resolution (250\,\unit{m}) result (see
Fig.~\ref{fig:3}) that can capture a detailed picture of the underlying bed topography. The fine-scale bumps and troughs are the result of the
DeepBedMap generator model learning to produce features that are similar to those found in the high-resolution ground-truth datasets it was trained
on. However, there are also artefacts produced by the model. For example, the winding terrace (T, Fig.~\ref{fig:4}) features are hard to
explain, and though they resemble eskers \citep{DrewsActivelyevolvingsubglacial2017}, their placement along the sides of hills does not support this
view. Similarly, we are not sure why speckle (S, Fig.~\ref{fig:4}) texture patterns are found over steep mountains, but the lack of high-resolution training datasets likely leads the model to perform worse over these high-gradient areas.

Another issue is that DeepBedMap will often pick up details from the high-resolution ice surface elevation model
\citep{HowatReferenceElevationModel2019} input dataset, which may not be representative of the true bed topography. For example, the ridges
(R, Fig.~\ref{fig:4}) found along fast-flowing ice streams and glaciers are likely to be the imprints of crevasses or flow stripes
\citep{GlasserLongitudinalsurfacestructures2012} observable from the surface. An alternative explanation is that the ridges, especially the
honeycomb-shaped ones, are rhombohedral moraine deposits formed by soft sediment squeezed up into basal crevasses that are sometimes found at stagnant
surging glaciers
\citep{Dowdeswellvarietydistributionsubmarine2016,DowdeswellRhombohedralcrevassefillridges2016,SolheimSeafloormorphologyoutside1985}. We favour the
first interpretation as the positions of these bed features coincide with the surface features and also because these ridges are more likely to be
eroded away in these fast-flowing ice stream areas.

\hack{\newpage}

The hummocky wave-like (W) patterns we observe over the relatively flat and slower-flowing areas are likely to result from surface megadune
structures \citep{ScambosSnowMegadune2014}. Alternatively, they may be ribbed or Rogen moraine features that are formed in an orientation transverse
to the ice flow direction \citep{HattestrandRibbedmorainesSweden1997,HattestrandRibbedmoraineformation1999}. While any one of these two explanations
may be valid in different regions of Antarctica, we lean towards the conservative interpretation that these features are the result of the DeepBedMap
model overfitting to the ice surface elevation data.

\subsection{Roughness}

In Sect.~\ref{section:surfaceroughness}, we quantitatively show that a well-trained DeepBedMap neural network model can produce high roughness values more
comparable to the ground truth than those of BedMachine Antarctica. While the mass conservation technique used by BedMachine Antarctica
\citep{MorlighemDeepglacialtroughs2019} improves upon ordinary interpolation techniques such as bicubic interpolation and kriging, its results are
still inherently smooth by nature. The ground-truth grids show that rough areas do exist on a fine scale, and so the high-resolution models we produce
should reflect that.

DeepBedMap\_DEM manages to capture much of the rough topography found in the Operation IceBridge ground-truth data, especially near the coast (see
Fig.~\ref{fig:6}a, from $-$1550 to $-$1500\,\unit{km} on the $x$~scale) where the terrain tends to be rougher. Along the retrograde slope (see
Fig.~\ref{fig:6}a, from $-$1500 to $-$1450\,\unit{km} on the $x$~scale), several of the fine-scale ($<$\,10\,\unit{km}) bumps and troughs in
DeepBedMap\_DEM can be seen to correlate well in position with the ground truth. In contrast, the cubically interpolated BedMachine Antarctica product
lacks such fine-scale ($<$\,10\,\unit{km}) bumps and troughs, appearing as a relatively smooth terrain over much of the transect. Previous studies
that estimated basal shear stress over Thwaites Glacier have found a band of strong bed extending about 80--100\,\unit{km} from the grounding line,
with pockets of weak bed interspersed between bands of strong bed further upstream
\citep{JoughinBasalconditionsPine2009,SergienkoRegularPatternsFrictional2013}, a pattern that is broadly consistent with the DeepBedMap\_DEM roughness
results (see Fig.~\ref{fig:5}b).

In general, DeepBedMap\_DEM produces a topography that is rougher, with SD values more in line with those observed in the ground truth (see
Fig.~\ref{fig:6}b). The roughness values for BedMachine Antarctica are consistently lower throughout the transect, a consequence of the mass
conservation technique using regularization parameters that yield smooth results. We note that the DeepBedMap\_DEM does appear rougher than the
ground truth in certain areas. It is possible to tweak the training regime to incorporate roughness (or any statistical measure) into the loss function
(see Appendix~\ref{appendix:A}) to yield the desired surface, and this will be explored in future work (see
Sect.~\ref{section:futuredirections}). Recent studies have stressed the importance of form drag (basal drag due to bed topography) over skin drag (or
basal friction) on the basal traction of Pine Island Glacier \citep{BinghamDiverselandscapesPine2017,Kyrke-SmithRelevanceDetailBasal2018}, and the
DeepBedMap super-resolution work here shows strong potential in meeting that demand as a high-resolution bed topography dataset for ice sheet
modelling studies.

In terms of bed roughness anisotropy, DeepBedMap is able to capture aspects of it from the ground-truth grids by combining (1)~ice flow direction via
the ice velocity grid's $x$ and $y$~components \citep{MouginotMEaSUREsPhaseMap2019}, (2)~ice surface aspect via the ice surface elevation grid
\citep{HowatReferenceElevationModel2019}, and (3)~the low-resolution bed elevation input \citep{FretwellBedmap2improvedice2013}. There are therefore
inherent assumptions that the topography of the current bed is associated with the current ice flow direction, surface aspect and existing low-resolution BEDMAP2 anisotropy. Provided that the direction of this surface velocity and aspect is the same as bed roughness anisotropy, as
demonstrated in \citet{HolschuhLinkingpostglaciallandscapes2020}, the neural network will be able to recognize it and perform accordingly. However, if
the ice flow direction and surface aspect is not associated with bed anisotropy, then this assumption will be violated and the model will not perform
well.


\subsection{Limitations}

The DeepBedMap model is trained only on a small fraction of the area of Antarctica, at less than 0.1\,{\%} of the grounded-ice regions (excluding ice
shelves and islands). This is because the pixel-based convolutional neural network cannot be trained on sparse survey point measurements, nor is it
able to constrain itself with track-based radar data. As the along-track resolution of radar bed picks are much smaller than 250\,\unit{m} pixels,
it is also not easy to preserve roughness from radar unless smaller pixels are used. The topography generated by the model is sensitive to the
accuracy of its data inputs (see Tables~\ref{table:groundtruthdata} and \ref{table:datainputs}), and though this is a problem faced by other inverse
methods, neural network models like the one presented can be particularly biased towards the training dataset. Specifically, the DeepBedMap model
focuses on resolving short-wavelength features important for sub-kilometre roughness, compared to BedMachine Antarctica
\citep{MorlighemDeepglacialtroughs2019} which recovers large-scale features like ridges and valleys well.

An inherent assumption in this methodology is that the training datasets have sampled the variable bed lithology of Antarctica
\citep{CoxGeoMAPdatasetAntarctic2018} sufficiently. This is unlikely to be true, introducing uncertainty into the result as different lithologies may
cause the same macroscale bed landscapes to result in a range of surface features. In particular, the experimental model's topography is likely
skewed towards the distribution of the training regions that tend to reside in coastal regions, especially over ice streams in West Antarctica (see
Fig.~\ref{fig:2}). While bed lithology could be used as an input to inform the DeepBedMap model's prediction, it is challenging to find a suitable
geological map (or geopotential proxy; \citealp[see e.g.][]{AitkensubglacialgeologyWilkes2014,CoxGeoMAPdatasetAntarctic2018}) for the entire Antarctic
continent that has a sufficiently high spatial resolution. Ideally, the lithological map (categorical or qualitative) would first be converted to a
hardness map with an appropriate erosion law and history incorporated (quantitative). This is because it is easier to train generative adversarial
networks on quantitative data (e.g. hardness as a scale from 0 to 10) than on categorical data variables (e.g. sedimentary, igneous or metamorphic
rocks); the latter would require a more elaborate model architecture and loss function design.


\subsection{Future directions}\label{section:futuredirections}

The way forward for DeepBedMap is to combine quality datasets gathered by radioglaciology and remote sensing specialists, with new advancements made
by the ice sheet modelling and machine learning community. While care has been taken to source the best possible datasets (see
Tables~\ref{table:groundtruthdata} and~\ref{table:datainputs}), we note that there are still areas where more data are needed. Radio-echo sounding is
the best tool available to fill in the data gap, as it provides not only the high-resolution datasets needed for training but also the background
coarse-resolution BEDMAP dataset. Besides targeting radio-echo-sounding acquisitions over a diverse range of bed and flow types, swath reprocessing
of old datasets that have that capability \citep{HolschuhLinkingpostglaciallandscapes2020} may be another useful addition to the training set. The
super-resolution DeepBedMap technique can also be applied on bed elevation inputs newer than BEDMAP2 \citep{FretwellBedmap2improvedice2013}, such as
the 1000\,\unit{m} resolution DEM over the Weddell Sea \citep{Jeofry1KmBedTopography2017}, the 500\,\unit{m} resolution BedMachine Antarctica dataset
\citep{MorlighemMEaSUREsBedMachineAntarctica2019} or the upcoming BEDMAP3.

A way to increase the number of high-resolution ground-truth training data further is to look at formerly glaciated beds. There are a wealth of data
around the margins of Antarctica in the form of swath bathymetry data and also on land in areas like the former Laurentide ice sheet. The current
model architecture does not support using solely ``elevation'' as an input, because it also requires ice elevation, ice surface velocity and snow
accumulation data. In order to support using these paleobeds as training data, one could do one of the following:
\begin{enumerate}
\item Have a paleo-ice-sheet model that provides these ice surface observation parameters. However, continent-scale ice sheet models quite often
  produce only kilometre-scale outputs, and there are inherent uncertainties with past ice sheet reconstructions that may bias the resulting trained
  neural network model.

\item Modularize the neural network model to support different sets of training data. One main branch would be trained like a single-image super-resolution problem \citep{YangDeepLearningSingle2019}, where we try to map a low-resolution BEDMAP2 tile to a high-resolution ground-truth image (be
  it from a contemporary bed, a paleobed or offshore bathymetry). The optional conditional branches would then act to support and improve on the result of this naive super-resolution method. This design is more complicated to set up and train, but it can increase the available training data by at least an order of magnitude and lead to better results.
\end{enumerate}
From a satellite remote sensing perspective, it is important to continue the work on increasing spatial coverage and measurement precision. Some of
the conditional datasets used such as REMA \citep{HowatReferenceElevationModel2019} and MEaSUREs Ice Velocity \citep{MouginotMEaSUREsPhaseMap2019}
contain data gaps which introduce artefacts in the DeepBedMap\_DEM, and those holes need to be patched up for proper continent-wide prediction. A surface mass balance dataset with sub-kilometre spatial resolution will also prove useful in replacing the snow accumulation dataset
\citep{ArthernAntarcticsnowaccumulation2006} used in this work. As the DeepBedMap model relies on data from multiple sources collected over different
epochs, it has no proper sense of time. Ice elevation change captured using satellite altimeters such as from CryoSat-2
\citep{HelmElevationelevationchange2014}, ICESat-2 \citep{MarkusIceCloudland2017} or the upcoming CRISTAL \citep{KernCopernicusPolarIce2020} could be
added as an additional input to better account for temporal factors.

The DeepBedMap model's modular design (see Sect.~\ref{section:modeldesign}) means the different modules (see Fig.~\ref{fig:1}) can be improved on and
adapted for future-use cases. The generator model architecture's input module can be modified to handle new datasets such as the ones suggested above
or redesigned to extract a greater amount of information for better performance. Similarly, the core and upsampling modules which are based on ESRGAN
\citep{WangESRGANEnhancedSuperResolution2019} can be replaced with newer, better architectures as the need arises. The discriminator model which is
currently one designed for standard computer vision tasks can also be modified to incorporate glaciology-specific criteria. For example, the generated
bed elevation image could be scrutinized by the discriminator model for valid properties such as topographic features that are aligned with the
ice flow direction. The redesigned neural network model can be retrained from scratch or fine-tuned using the trained weights from DeepBedMap to
further improve the predictive performance. Taken together, these advances will lead to an even more accurate and higher-resolution bed elevation
model.


\conclusions

The DeepBedMap convolutional neural network method presents a data-driven approach to resolve the bed topography of Antarctica using existing data. It
is an improvement beyond simple interpolation techniques, generating high-spatial-resolution (250\,\unit{m}) topography that preserves detail in bed
roughness and is adaptable for catchment- to continent-scale studies on ice sheets. Unlike other inverse methods that rely on some explicit
parameterization of ice flow physics, the model uses deep learning to find suitable neural network parameters via an iterative error minimization
approach. This makes the resulting model particularly sensitive to the training dataset, emphasizing the value of densely spaced bed elevation
datasets and the need for such sampling over a more diverse range of Antarctic substrate types. The use of graphical processing units (GPUs) for
training and inference allows the neural network method to scale easily, and the addition of more training datasets will allow it to perform better.

The work here is intended not to discourage the usage of other inverse modelling or spatial statistical techniques but to introduce an alternative
methodology, with an outlook towards combining each methodology's strengths. Once properly trained, the DeepBedMap model runs quickly (about 3\,min for the
whole Antarctic continent) and produces realistic rough topography. Combining the DeepBedMap model with more physically based mass conservation
inverse approaches \citep[e.g.][]{MorlighemDeepglacialtroughs2019} will likely result in more efficient ways of generating accurate bed elevation maps
of Antarctica. One side product resulting from this work is a test-driven development framework that can be used to measure and compare the
performance of upcoming bed terrain models. The radioglaciology community has already begun to compile a new comprehensive bed elevation and ice thickness dataset for Antarctica, and there have been discussions on combining various terrain interpolation techniques in an ensemble to collaboratively create
the new BEDMAP3.


\hack{\clearpage}

\appendix

\section{Details of loss function components}\label{appendix:A}

The loss function, or cost function, is a mathematical function that maps a set of input variables to an output loss value. The loss value can be
thought of as a weighted sum of several error metrics between the neural network's prediction and the expected output or ground truth. It is this loss
value which we want to minimize so as to train the neural network model to perform better, and we do this by iteratively optimizing the parameters in
the loss function. Following this are the details of the various loss functions that make up the total loss function of the DeepBedMap generative
adversarial network model.


\subsection{Content loss}

To bring the pixel values of the generated images closer to those of the ground truth, we first define the content-loss function~$L_1$. Following ESRGAN
\citep{WangESRGANEnhancedSuperResolution2019}, we have
\begin{equation}\label{eq:A1}
L_1 = \dfrac{1}{n} \sum\limits_{i=1}^n ||\hat{y}_i - y_i||_{1}~,
\end{equation}
where we take the mean absolute error between the generator network's predicted value~$\hat{y}_i$ and the ground-truth value~$y_i$, respectively, over
every pixel $i$.


\subsection{Adversarial loss}

Next, we define an adversarial loss to encourage the production of high-resolution images~$\hat{y}$ closer to the manifold of natural-looking digital-elevation-model images. To do so, we introduce the standard discriminator in the form of $D(y) = \sigma(C(y))$, where~$\sigma$ is the sigmoid
activation function and $C(y)$ is the raw, non-transformed output from a discriminator neural network acting on high-resolution image~$y$. The ESRGAN
model \citep{WangESRGANEnhancedSuperResolution2019}, however, employs an improved relativistic-average discriminator
\citep{Jolicoeur-Martineaurelativisticdiscriminatorkey2018} denoted by~$D_{\text{Ra}}$. It is defined as $D_{\text{Ra}}(y,\hat{y}) = \sigma(C(y) -
\mathbb{E}_{\hat{y}}[C(\hat{y})])$, where $\mathbb{E}_{\hat{y}}[\cdot]$ is the arithmetic mean operation carried out over every generated image
$\hat{y}$ in a mini batch. We use a binary cross-entropy loss as the discriminator's loss function defined as follows:
\begin{equation}\label{eq:A2}
L_{\mathrm{D}}^{\text{Ra}} = - \mathbb{E}_y[\ln(D(y,\hat{y}))] - \mathbb{E}_{\hat{y}}[\ln(1 - D(\hat{y},y))].
\end{equation}

The generator network's adversarial loss is in a symmetrical form:
\begin{equation}\label{eq:A3}
L_{\mathrm{G}}^{\text{Ra}} = - \mathbb{E}_y[\ln(1 - D(y,\hat{y}))] - \mathbb{E}_{\hat{y}}[\ln(D(\hat{y},y))].
\end{equation}


\subsection{Topographic loss}

We further define a topographic loss so that the elevation values in the super-resolved image make topographic sense with respect to the original low-resolution image. Specifically, we want the mean value of each 4\,$\times$\,4 grid on the predicted super-resolution (DeepBedMap) image to closely
match its spatially corresponding 1\,\unit{pixel}\,$\times$\,1\,\unit{pixel} area on the low-resolution (BEDMAP2) image.

First, we apply a 4\,$\times$\,4 mean pooling operation on the generator network's predicted super-resolution image:
\begin{equation}\label{eq:A4}
\bar{\hat{y}}_j = \dfrac{1}{n} \sum\limits_{i=1}^n \hat{y}_i~,
\end{equation}
where $\bar{\hat{y}}_j$ is the mean of all predicted values~$\hat{y}_i$ across the 16 super-resolved pixels~$i$ within a 4\,$\times$\,4 grid
corresponding to the spatial location of 1 low-resolution pixel at position $j$. Following this, we can compute the topographic loss as follows:
\begin{equation}\label{eq:A5}
L_{\mathrm{T}} = \dfrac{1}{m} \sum\limits_{i=1}^m ||\bar{\hat{y}}_j - x_j||_{1}~,
\end{equation}
where we take the mean absolute error between the mean of the 4\,$\times$\,4 super-resolved pixels calculated in Eq.~(\ref{eq:A4}) $\bar{\hat{y}}_j$
and those of the spatially corresponding low-resolution pixel~$x_j$, respectively, over every low-resolution pixel~$j$.


\subsection{Structural loss}

Lastly, we define a structural loss that takes into account luminance, contrast and structural information between the predicted and ground-truth
images. This is based on the structural similarity index \citep[SSIM;][]{WangImageQualityAssessment2004} and is calculated over a single window patch as
\begin{equation}\label{eq:A6}
\text{SSIM} (\hat{y}, y) = \dfrac{(2\mu_{\hat{y}}\mu_y + c_1)(2\sigma_{{\hat{y}}y} + c_2)}{(\mu_{\hat{y}}^2 + \mu_y^2 + c_1)(\sigma_{\hat{y}}^2 + \sigma_y^2 + c_2)},
\end{equation}
where $\mu_{\hat{y}}$ and $\mu_y$ are the arithmetic mean of predicted image~${\hat{y}}$ and ground-truth image~$y$, respectively, over a single window
that we set to 9~pixels\,$\times$\,9~pixels; $\sigma_{{\hat{y}}y}$ is the covariance of~${\hat{y}}$ and~$y$; $\sigma_{\hat{y}}^2$ and $\sigma_y^2$ are the
variances of~${\hat{y}}$ and~$y$, respectively; and~$c_1$ and~$c_2$ are two variables set to $0.01^2$ and $0.03^2$ to stabilize division with a weak
denominator. Thus, we can formulate the structural loss as follows:
\begin{equation}\label{eq:A7}
L_{\mathrm{S}} = 1 - \dfrac{1}{p} \sum\limits_{i=1}^p \text{SSIM} (\hat{y}, y)_p~,
\end{equation}
where we take $1$ minus the mean of all structural similarity values $\text{SSIM}(\hat{y}, y)$ calculated over every patch~$p$ obtained via a sliding
window over the predicted image~${\hat{y}}$ and ground-truth image~$y$.


\subsection{Total loss function}

Finally, we compile the loss functions for the discriminator and generator networks as follows:
\begin{align}
& L_{\mathrm{D}} = L_{\mathrm{D}}^{\text{Ra}}, \label{eq:A8}\\
& L_{\mathrm{G}} = \eta L_1 + \lambda L_{\mathrm{G}}^{\text{Ra}} + \theta L_{\mathrm{T}} + \zeta L_{\mathrm{S}}~, \label{eq:A9}
\end{align}
where $\eta$, $\lambda$, $\theta$ and $\zeta$ are the scaled weights for the content $L_1$, adversarial $L_{\mathrm{D}}$, topographic
$L_{\mathrm{T}}$ and structural losses $L_{\mathrm{S}}$, respectively (see Table~\ref{table:B1} for values used). The loss functions $L_{\mathrm{D}}$
and $L_{\mathrm{G}}$ are minimized in an alternate $1:1$ manner so as to solve the entire generative adversarial network's objective function defined in
Eq.~(\ref{eq:4}).


\section{Neural network training details}\label{appendix:B}

The neural networks were developed using Chainer v7.0.0 \citep{TokuiChainerDeepLearning2019} and trained using full-precision (floating point 32)
arithmetic. Experiments were carried out on four graphical processing units (GPUs), specifically two Tesla P100 GPUs and two Tesla V100 GPUs. On the Tesla V100 GPU setup, one training run with about 150 epochs takes about 30\,min. This is using a batch size of 128 on a total of 3826 training image tiles,
with 202 tiles reserved for validation, i.e. a $95/5$ training/validation split. We next describe the method used to evaluate each DeepBedMap
candidate model, as well as the high-level way in which we semi-automatically arrived at a good model via semi-automatic hyperparameter tuning.

To check for overfitting, we evaluate the generative adversarial network model using the validation dataset after each epoch using two performance
metrics~-- a peak signal-to-noise ratio (PSNR) metric for the generator and an accuracy metric for the discriminator. Training stops when these
validation performance metrics show little improvement, roughly at 140~epochs.

%TB1
\begin{table}[h!]
\hack{\hsize\textwidth}
\caption{Optimized hyperparameter settings.}
\label{table:B1}
\begin{tabular}{lrr}
\tophline
Hyperparameter                                       & Setting             & Tuning range                           \\\middlehline
Learning rate (for both generator and discriminator) & $1.7\times 10^{-4}$ & $2\times 10^{-4}$ to $1\times 10^{-4}$ \\
Number of residual-in-residual blocks                & 12                  & 8 to 14                                \\
Mini-batch size                                      & 128                 & 64 or 128                              \\
Number of epochs                                     & 140                 & 90 to 150                              \\
Residual scaling                                     & 0.2                 & 0.1 to 0.5                             \\
Content-loss weighting $\eta$                        & $1\times 10^{-2}$   & Fixed                                  \\
Adversarial-loss weighting $\lambda$                 & $2\times 10^{-2}$   & Fixed                                  \\
Topographic-loss weighting $\theta$                  & $2\times 10^{-3}$   & Fixed                                  \\
Structural-loss weighting $\zeta$                    & 5.25                & Fixed                                  \\
He normal initialization scaling                     & 0.1                 & Fixed                                  \\
Adam optimizer epsilon                               & 0.1                 & Fixed                                  \\
Adam optimizer beta1                                 & 0.9                 & Fixed                                  \\
Adam optimizer beta2                                 & 0.99                & Fixed                                  \\
\bottomhline
\end{tabular}
\end{table}

Next, we conduct a full evaluation on an independent test dataset, comparing the model's predicted grid output with actual ground-truth \textit{xyz} points. Using the ``grdtrack'' function in Generic Mapping Tools v6.0 \citep{WesselGenericMappingTools2019}, we obtain the grid elevation at each
ground-truth point and use it to calculate the elevation error on a point-to-point basis. All of these elevation errors are then used to compute a root
mean square error (RMSE) statistic over this independent test site. This RMSE value is used to judge the model's performance in relation to baseline
bicubic interpolation and is also the metric minimized by a hyperparameter optimization algorithm which we will describe next.


Neural networks contain a lot of hyperparameter settings that need to be decided upon, and generative adversarial networks are particularly sensitive
to different hyperparameter settings. To stabilize model training and obtain better performance, we tune the hyperparameters (see
Table~\ref{table:B1}) using a Bayesian approach. Specifically, we employ the Tree-structured Parzen Estimator
\citep{BergstraAlgorithmsHyperparameterOptimization2011} from the Optuna v2.0.0 \citep{AkibaOptunaNextgenerationHyperparameter2019} library with
default settings as per the Hyperopt library \citep{BergstraHyperoptPythonlibrary2015}. Given that we have four GPUs, we choose to parallelize the
hyperparameter tuning experiments asynchronously between all four devices. The estimator first conducts 20 random experimental trials to scan the
hyperparameter space, gradually narrowing down its range to a few candidate hyperparameters in subsequent experiments. We set each GPU to run a target of 60
experimental trials (i.e. a total of 240), though unpromising trials that have exploding or vanishing gradients are pruned prematurely using the
Hyperband algorithm \citep{LiHyperbandNovelBanditBased2018} to save on time and computational resources. The top models from these experiments undergo
further visual evaluation, and we continue to conduct further experiments until a suitable candidate model is found.


\hack{\clearpage}



\codeavailability{Python code for data preparation, neural network model training and visualization of model outputs is freely available at
  \url{https://github.com/weiji14/deepbedmap} (last access: 9~August~2020) and at \doi{10.5281/zenodo.3752613} \citep{LeongHorgan2020b}. Neural network model training
  experiment runs are also recorded at \url{https://www.comet.ml/weiji14/deepbedmap} (last access: 9~August~2020).}


\dataavailability{The DeepBedMap\_DEM is available from Zenodo at \doi{10.5281/zenodo.3752613}  \citep{LeongHorgan2020b}. The Pine Island Glacier dataset \citep{BinghamDiverselandscapesPine2017} is available on request from Robert Bingham. The Carlson Inlet dataset \citep{KingIcestreamnot2011} is available on request from Edward King. Bed elevation datasets from Wilkes Subglacial Basin \citep{FerraccioliAirborneradarbed2018} and Rutford Ice Stream \citep{KingSubglaciallandformsRutford2016} are available from the British Antarctic Survey's Polar Data Centre (\url{https://ramadda.data.bas.ac.uk}, last access: 14~January~2020). Other Antarctic bed elevation datasets are available from the Center for Remote Sensing of Ice Sheets (\url{https://data.cresis.ku.edu/data/rds}, last access: 15~August~2019) or from the National Snow and Ice Data Center (\url{https://nsidc.org/data/IRMCR2/versions/1}, last access: 15~August~2019). BEDMAP2 \citep{FretwellBedmap2improvedice2013} and REMA \citep{HowatReferenceElevationModel2018} are available from the Polar Geospatial Center (\url{http://data.pgc.umn.edu}, last access: 30~August~2019). MEaSUREs Ice Velocity data \citep{MouginotMEaSUREsPhaseMap2019} are available from NSIDC (\url{https://nsidc.org/data/nsidc-0754/versions/1}, last access: 31~August~2019). Antarctic snow accumulation data \citep{ArthernAntarcticsnowaccumulation2006} are available from the British Antarctic Survey (\url{https://secure.antarctica.ac.uk/data/bedmap2/resources/Arthern_accumulation}, last access: 17~June~2019).}


\authorcontribution{WJL was responsible for data curation, formal analysis, methodology, software, visualization and writing the original draft. HJH was responsible for funding acquisition and supervision. Both authors conceptualized the work and contributed to the reviewing and editing stages of the writing.}



\competinginterests{The authors declare that they have no conflict of interest.}


\begin{acknowledgements}
  We are grateful to Robert Bingham and Edward King for the Pine Island Glacier and Carlson Inlet data and to all the other researchers in the
  British Antarctic Survey and Operation IceBridge team for providing free access to the high-resolution bed elevation datasets around Antarctica. A
  special thanks to Ruzica Dadic for her help in reviewing draft versions of this paper. This research was funded by the Royal Society of New
  Zealand's Rutherford Discovery Fellowship (contract RDF-VUW1602), with additional support from the Erasmus+ programme and International
  Glaciological Society early-career travel award for presenting earlier versions of this work at the 2019 EGU General Assembly and IGS Symposium on
  Five Decades of Radioglaciology.
\end{acknowledgements}


\financialsupport{This research has been supported by the Royal Society of New Zealand (Rutherford Discovery Fellowship -- contract no.~RDF-VUW1602).}


\reviewstatement{This paper was edited by Olivier~Gagliardini and reviewed by Martin~Siegert and one anonymous referee.}



\begin{thebibliography}{95}

\bibitem[{Aitken et~al.(2014)}]{AitkensubglacialgeologyWilkes2014}
Aitken, A. R. A., Young, D. A., Ferraccioli, F., Betts, P. G., Greenbaum, J. S., Richter, T. G., Roberts, J. L., Blankenship, D. D., and Siegert, M. J.: The subglacial geology of Wilkes Land, East Antarctica, Geophys. Res. Lett., 41, 2390--2400, \doi{10.1002/2014GL059405}, 2014.

\bibitem[{Akiba et~al.(2019)Akiba, Sano, Yanase, Ohta, and Koyama}]{AkibaOptunaNextgenerationHyperparameter2019}
Akiba, T., Sano, S., Yanase, T., Ohta, T., and Koyama, M.: Optuna: A Next-generation Hyperparameter Optimization Framework, in: Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining  -- KDD '19, ACM Press, Anchorage, AK, USA, \doi{10.1145/3292500.3330701}, 2623--2631, 4--8~August~2019.

\bibitem[{Arthern et~al.(2006)}]{ArthernAntarcticsnowaccumulation2006}
Arthern, R. J., Winebrenner, D. P., and Vaughan, D. G.: Antarctic snow accumulation mapped using polarization of 4.3-cm wavelength microwave emission, J. Geophys. Res., 111, D06107, \doi{10.1029/2004JD005667}, 2006.


\bibitem[{Bergstra et~al.(2011)}]{BergstraAlgorithmsHyperparameterOptimization2011}
Bergstra, J., Bardenet, R., Bengio, Y., and K{\'e}gl, B.:
Algorithms for Hyper-Parameter Optimization, in: Proceedings of the 24th International Conference on Neural Information Processing Systems, NIPS'11, Curran Associates Inc., Granada, Spain, 2546--2554, 2011.

\bibitem[{Bergstra et~al.(2015)Bergstra, Komer, Eliasmith, Yamins, and Cox}]{BergstraHyperoptPythonlibrary2015}
Bergstra, J., Komer, B., Eliasmith, C., Yamins, D., and Cox, D.~D.:
Hyperopt: A Python Library for Model Selection and Hyperparameter Optimization,
Computational Science \& Discovery,
8, 014008, \doi{10.1088/1749-4699/8/1/014008}, 2015.

\bibitem[{Bindschadler et~al.(2011)Bindschadler, Choi, Wichlacz, Bingham, Bohlander, Brunt, Corr, Drews, Fricker, Hall, Hindmarsh, Kohler, Padman, Rack, Rotschky, Urbini, Vornberger, and Young}]{BindschadlerGettingAntarcticanew2011}
Bindschadler, R., Choi, H., Wichlacz, A., Bingham, R., Bohlander, J., Brunt, K., Corr, H., Drews, R., Fricker, H., Hall, M., Hindmarsh, R., Kohler, J., Padman, L., Rack, W., Rotschky, G., Urbini, S., Vornberger, P., and Young, N.: Getting around Antarctica: new high-resolution mappings of the grounded and freely-floating boundaries of the Antarctic ice sheet created for the International Polar Year, The Cryosphere, 5, 569--588, \doi{10.5194/tc-5-569-2011}, 2011.

\bibitem[{Bingham et~al.(2017)Bingham, Vaughan, King, Davies, Cornford, Smith, Arthern, Brisbourne, De~Rydt, Graham, Spagnolo, Marsh, and Shean}]{BinghamDiverselandscapesPine2017}
Bingham, R. G., Vaughan, D. G., King, E. C., Davies, D., Cornford, S. L., Smith, A. M., Arthern, R. J., Brisbourne, A. M., De Rydt, J., Graham, A. G. C., Spagnolo, M., Marsh, O. J., and Shean, D. E.: Diverse landscapes beneath Pine Island Glacier influence ice flow, Nat. Commun., 8, 1618, \doi{10.1038/s41467-017-01597-y}, 2017.

\bibitem[{Blau et~al.(2018)Blau, Mechrez, Timofte, Michaeli, and {Zelnik-Manor}}]{Blau2018PIRMChallenge2018}
Blau, Y., Mechrez, R., Timofte, R., Michaeli, T., and Zelnik-Manor, L.: 2018 PIRM Challenge on Perceptual Image Super-resolution, arXiv:1809.07517 [cs], 2018.


\bibitem[{Chen et~al.(2016)Chen, Wang, Xu, and Hou}]{ChenConvolutionalNeuralNetwork2016}
Chen, Z., Wang, X., Xu, Z., and Hou, W.:
Convolutional Neural Network Based Dem Super Resolution, ISPRS~-- International Archives of the Photogrammetry,
Remote Sensing and Spatial Information Sciences,
XLI-B3, 247--250, \doi{10.5194/isprsarchives-XLI-B3-247-2016}, 2016.

\bibitem[{Clarke et~al.(2009)Clarke, Berthier, Schoof, and Jarosch}]{ClarkeNeuralNetworksApplied2009}
Clarke, G. K.~C., Berthier, E., Schoof, C.~G., and Jarosch, A.~H.:
Neural Networks Applied to Estimating Subglacial Topography and Glacier Volume,
J. Climate,
22, 2146--2160, \doi{10.1175/2008JCLI2572.1}, 2009.

\bibitem[{Cornford et~al.(2016)Cornford, Martin, Lee, Payne, and Ng}]{CornfordAdaptivemeshrefinement2016}
Cornford, S.~L., Martin, D.~F., Lee, V., Payne, A.~J., and Ng, E.~G.:
Adaptive Mesh Refinement versus Subgrid Friction Interpolation in Simulations of Antarctic Ice Dynamics,
Ann. Glaciol.,
57, 1--9, \doi{10.1017/aog.2016.13}, 2016.

\bibitem[{Cox et~al.(2018)Cox, {Smith-Lyttle}, Siddoway, Capponi, Elvevold, {Burton-Johnson}, Halpin, Morin, Elliot, and {Geomap Action Group}}]{CoxGeoMAPdatasetAntarctic2018}
Cox, S. C., Smith-Lyttle, B., Siddoway, C., Capponi, G., Elvevold, S., Burton-Johnson, A., Halpin, J., Morin, P., Elliot, D., and Geomap Action Group: The GeoMAP dataset of Antarctic rock exposures, in: POLAR2018, p. 2428, Davos, Switzerland, 19--23~June~2018.


\bibitem[{Dai et~al.(2017)Dai, Qi, Xiong, Li, Zhang, Hu, and Wei}]{DaiDeformableConvolutionalNetworks2017}
Dai, J., Qi, H., Xiong, Y., Li, Y., Zhang, G., Hu, H., and Wei, Y.:
Deformable Convolutional Networks,
arXiv:1703.06211 [cs], 2017.

\bibitem[{Dong et~al.(2014)Dong, Loy, He, and Tang}]{DongImageSuperResolutionUsing2014}
Dong, C., Loy, C.~C., He, K., and Tang, X.:
Image Super-Resolution Using Deep Convolutional Networks,
arXiv:1501.00092 [cs], 2014.

\bibitem[{Dowdeswell et~al.(2016{\natexlab{a}})Dowdeswell, Canals, Jakobsson, Todd, Dowdeswell, and Hogan}]{Dowdeswellvarietydistributionsubmarine2016}
Dowdeswell, J.~A., Canals, M., Jakobsson, M., Todd, B.~J., Dowdeswell, E.~K., and Hogan, K.~A.:
The Variety and Distribution of Submarine Glacial Landforms and Implications for Ice-Sheet Reconstruction,
Geol. Soc. Mem.,
46, 519--552, \doi{10.1144/M46.183}, 2016{\natexlab{a}}.

\bibitem[{Dowdeswell et~al.(2016{\natexlab{b}})Dowdeswell, Solheim, and Ottesen}]{DowdeswellRhombohedralcrevassefillridges2016}
Dowdeswell, J.~A., Solheim, A., and Ottesen, D.:
Rhombohedral Crevasse-Fill Ridges at the Marine Margin of a Surging Svalbard Ice Cap,
Geol. Soc. Mem.,
46, 73--74, \doi{10.1144/M46.62}, 2016{\natexlab{b}}.

\bibitem[{Drews et~al.(2017)Drews, Pattyn, Hewitt, Ng, Berger, Matsuoka, Helm, Bergeot, Favier, and Neckel}]{DrewsActivelyevolvingsubglacial2017}
Drews, R., Pattyn, F., Hewitt, I. J., Ng, F. S. L., Berger, S., Matsuoka, K., Helm, V., Bergeot, N., Favier, L., and Neckel, N.: Actively evolving subglacial conduits and eskers initiate ice shelf channels at an Antarctic grounding line, Nat. Commun., 8, 15228, \doi{10.1038/ncomms15228}, 2017.

\bibitem[{Dumoulin et~al.(2018)Dumoulin, Perez, Schucher, Strub, Vries, Courville, and Bengio}]{DumoulinFeaturewisetransformations2018}
Dumoulin, V., Perez, E., Schucher, N., Strub, F., Vries, H., Courville, A., and Bengio, Y.: Feature-wise transformations, Distill, 3, e11, \doi{10.23915/distill.00011}, 2018.

\bibitem[{Durand et~al.(2011)Durand, Gagliardini, Favier, Zwinger, and {le Meur}}]{DurandImpactbedrockdescription2011}
Durand, G., Gagliardini, O., Favier, L., Zwinger, T., and {le Meur}, E.:
Impact of Bedrock Description on Modeling Ice Sheet Dynamics: Bedrock Description to Model Ice Sheet,
Geophys. Res. Lett.,
38, \doi{10.1029/2011GL048892}, 2011.


\bibitem[{Falcini et~al.(2018)Falcini, Rippin, Krabbendam, and Selby}]{FalciniQuantifyingbedroughness2018}
Falcini, F.~A., Rippin, D.~M., Krabbendam, M., and Selby, K.~A.:
Quantifying Bed Roughness beneath Contemporary and Palaeo-Ice Streams,
J. Glaciol.,
64, 822--834, \doi{10.1017/jog.2018.71}, 2018.

\bibitem[{Farinotti et~al.(2009)Farinotti, Huss, Bauder, Funk, and Truffer}]{Farinottimethodestimateice2009}
Farinotti, D., Huss, M., Bauder, A., Funk, M., and Truffer, M.:
A Method to Estimate the Ice Volume and Ice-Thickness Distribution of Alpine Glaciers,
J. Glaciol.,
55, 422--430, \doi{10.3189/002214309788816759}, 2009.

\bibitem[{Farinotti et~al.(2017)Farinotti, Brinkerhoff, Clarke, F{\"u}rst, Frey, Gantayat, {Gillet-Chaulet}, Girard, Huss, Leclercq, Linsbauer, Machguth, Martin, Maussion, Morlighem, Mosbeux, Pandit, Portmann, Rabatel, Ramsankaran, Reerink, Sanchez, Stentoft, Singh~Kumari, {van Pelt}, Anderson, Benham, Binder, Dowdeswell, Fischer, Helfricht, Kutuzov, Lavrentiev, McNabb, Gudmundsson, Li, and Andreassen}]{FarinottiHowaccurateare2017}
Farinotti, D., Brinkerhoff, D. J., Clarke, G. K. C., F"{u}rst, J. J., Frey, H., Gantayat, P., Gillet-Chaulet, F., Girard, C., Huss, M., Leclercq, P. W., Linsbauer, A., Machguth, H., Martin, C., Maussion, F., Morlighem, M., Mosbeux, C., Pandit, A., Portmann, A., Rabatel, A., Ramsankaran, R., Reerink, T. J., Sanchez, O., Stentoft, P. A., Singh Kumari, S., van Pelt, W. J. J., Anderson, B., Benham, T., Binder, D., Dowdeswell, J. A., Fischer, A., Helfricht, K., Kutuzov, S., Lavrentiev, I., McNabb, R., Gudmundsson, G. H., Li, H., and Andreassen, L. M.: How accurate are estimates of glacier ice thickness? Results from ITMIX, the Ice Thickness Models Intercomparison eXperiment, The Cryosphere, 11, 949--970, \doi{10.5194/tc-11-949-2017}, 2017.

\bibitem[{Farinotti et~al.(2019)Farinotti, Huss, F{\"u}rst, Landmann, Machguth, Maussion, and Pandit}]{Farinotticonsensusestimateice2019}
Farinotti, D., Huss, M., F{\"u}rst, J.~J., Landmann, J., Machguth, H., Maussion, F., and Pandit, A.:
A Consensus Estimate for the Ice Thickness Distribution of All Glaciers on Earth,
Nat. Geosci.,
12, 168--173, \doi{10.1038/s41561-019-0300-3}, 2019.

\bibitem[{Ferraccioli et~al.(2018)Ferraccioli, Corr, Jordan, Robinson, Armadillo, Armadillo, and Armadillo}]{FerraccioliAirborneradarbed2018}
Ferraccioli, F., Corr, H., Jordan, T. A., Robinson, C., Armadillo, E., Bozzo, E., and Caneva, G.: Airborne radar bed elevation picks across the Wilkes Subglacial Basin, 2005--2006, Polar Data Centre, Natural Environment Research Council, UK, \doi{10.5285/59e5a6f5-e67d-4a05-99af-30f656569401}, 3~April~2018.

\bibitem[{Fretwell et~al.(2013)}]{FretwellBedmap2improvedice2013}
Fretwell, P., Pritchard, H. D., Vaughan, D. G., Bamber, J. L., Barrand, N. E., Bell, R., Bianchi, C., Bingham, R. G., Blankenship, D. D., Casassa, G., Catania, G., Callens, D., Conway, H., Cook, A. J., Corr, H. F. J., Damaske, D., Damm, V., Ferraccioli, F., Forsberg, R., Fujita, S., Gim, Y., Gogineni, P., Griggs, J. A., Hindmarsh, R. C. A., Holmlund, P., Holt, J. W., Jacobel, R. W., Jenkins, A., Jokat, W., Jordan, T., King, E. C., Kohler, J., Krabill, W., Riger-Kusk, M., Langley, K. A., Leitchenkov, G., Leuschen, C., Luyendyk, B. P., Matsuoka, K., Mouginot, J., Nitsche, F. O., Nogi, Y., Nost, O. A., Popov, S. V., Rignot, E., Rippin, D. M., Rivera, A., Roberts, J., Ross, N., Siegert, M. J., Smith, A. M., Steinhage, D., Studinger, M., Sun, B., Tinto, B. K., Welch, B. C., Wilson, D., Young, D. A., Xiangbin, C., and Zirizzotti, A.: Bedmap2: improved ice bed, surface and thickness datasets for Antarctica, The Cryosphere, 7, 375--393, \doi{10.5194/tc-7-375-2013}, 2013.

\bibitem[{Fukushima and Miyake(1982)}]{FukushimaNeocognitronnewalgorithm1982}
Fukushima, K. and Miyake, S.:
Neocognitron: A New Algorithm for Pattern Recognition Tolerant of Deformations and Shifts in Position,
Pattern Recogn.,
15, 455--469, \doi{10.1016/0031-3203(82)90024-3}, 1982.


\bibitem[{GEBCO Bathymetric Compilation Group(2020)}]{GEBCOCompilationGroupGEBCO2020Grid2020}
GEBCO Bathymetric Compilation Group: The GEBCO\_2020 Grid -- a continuous terrain model of the global oceans and land. British Oceanographic Data Centre, National Oceanography Centre, NERC, UK, \doi{10.5285/a29c5465-b138-234d-e053-6c86abc040b9}, 2020.

\bibitem[{Glasser and Gudmundsson(2012)}]{GlasserLongitudinalsurfacestructures2012}
Glasser, N. F. and Gudmundsson, G. H.: Longitudinal surface structures (flowstripes) on Antarctic glaciers, The Cryosphere, 6, 383--391, \doi{10.5194/tc-6-383-2012}, 2012.

\bibitem[{Goff et~al.(2014)Goff, Powell, Young, and Blankenship}]{GoffConditionalsimulationThwaites2014}
Goff, J.~A., Powell, E.~M., Young, D.~A., and Blankenship, D.~D.:
Conditional Simulation of Thwaites Glacier (Antarctica) Bed Topography for Flow Models: Incorporating Inhomogeneous Statistics and Channelized Morphology,
J. Glaciol.,
60, 635--646, \doi{10.3189/2014JoG13J200}, 2014.

\bibitem[{Goodfellow et~al.(2014)Goodfellow, {Pouget-Abadie}, Mirza, Xu, {Warde-Farley}, Ozair, Courville, and Bengio}]{GoodfellowGenerativeAdversarialNetworks2014}
Goodfellow, I.~J., {Pouget-Abadie}, J., Mirza, M., Xu, B., {Warde-Farley}, D., Ozair, S., Courville, A., and Bengio, Y.:
Generative Adversarial Networks,
arXiv:1406.2661 [cs, stat], 2014.

\bibitem[{Graham et~al.(2017)Graham, Roberts, {Galton-Fenzi}, Young, Blankenship, and Siegert}]{Grahamhighresolutionsyntheticbed2017}
Graham, F. S., Roberts, J. L., Galton-Fenzi, B. K., Young, D., Blankenship, D., and Siegert, M. J.: A high-resolution synthetic bed elevation grid of the Antarctic continent, Earth Syst. Sci. Data, 9, 267--279, \doi{10.5194/essd-9-267-2017}, 2017.


\bibitem[{H{\"a}ttestrand(1997)}]{HattestrandRibbedmorainesSweden1997}
H{\"a}ttestrand, C.:
Ribbed Moraines in Sweden~-- Distribution Pattern and Palaeoglaciological Implications,
Sediment. Geol.,
111, 41--56, \doi{10.1016/S0037-0738(97)00005-5}, 1997.

\bibitem[{H{\"a}ttestrand and Kleman(1999)}]{HattestrandRibbedmoraineformation1999}
H{\"a}ttestrand, C. and Kleman, J.:
Ribbed Moraine Formation,
Quaternary Sci. Rev.,
18, 43--61, \doi{10.1016/S0277-3791(97)00094-2}, 1999.

\bibitem[{He et~al.(2015)He, Zhang, Ren, and Sun}]{HeDeepResidualLearning2015}
He, K., Zhang, X., Ren, S., and Sun, J.:
Deep Residual Learning for Image Recognition,
arXiv:1512.03385 [cs], 2015.

\bibitem[{He et~al.(2016)He, Zhang, Ren, and Sun}]{HeIdentityMappingsDeep2016}
He, K., Zhang, X., Ren, S., and Sun, J.:
Identity Mappings in Deep Residual Networks,
arXiv:1603.05027 [cs], 2016.

\bibitem[{Helm et~al.(2014)Helm, Humbert, and Miller}]{HelmElevationelevationchange2014}
Helm, V., Humbert, A., and Miller, H.: Elevation and elevation change of Greenland and Antarctica derived from CryoSat-2, The Cryosphere, 8, 1539--1559, \doi{10.5194/tc-8-1539-2014}, 2014.

\bibitem[{Holschuh et~al.(2020)Holschuh, Christianson, Paden, Alley, and Anandakrishnan}]{HolschuhLinkingpostglaciallandscapes2020}
Holschuh, N., Christianson, K., Paden, J., Alley, R. B., and Anandakrishnan, S.: Linking postglacial landscapes to glacier dynamics using swath radar at Thwaites Glacier, Antarctica, Geology, 48, 268--272, \doi{10.1130/G46772.1}, 2020.

\bibitem[{Howat et~al.(2018)}]{HowatReferenceElevationModel2018}
Howat, I. M., Paul, M., Claire, P., and Myong-Jong, N.: The Reference Elevation Model of Antarctica, Harvard Dataverse, \doi{10.7910/DVN/SAIK8B}, 2018.

\bibitem[{Howat et~al.(2019)}]{HowatReferenceElevationModel2019}
Howat, I. M., Porter, C., Smith, B. E., Noh, M.-J., and Morin, P.: The Reference Elevation Model of Antarctica, The Cryosphere, 13, 665--674, \doi{10.5194/tc-13-665-2019}, 2019.


\bibitem[{{IMBIE}(2018)}]{IMBIEMassbalanceAntarctic2018}
{IMBIE}:
Mass Balance of the Antarctic Ice Sheet from 1992 to 2017,
Nature,
558, 219--222, \doi{10.1038/s41586-018-0179-y}, 2018.

\bibitem[{Ioffe and Szegedy(2015)}]{IoffeBatchNormalizationAccelerating2015}
Ioffe, S. and Szegedy, C.:
Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift,
arXiv:1502.03167 [cs], 2015.

\bibitem[{Isola et~al.(2016)Isola, Zhu, Zhou, and Efros}]{IsolaImagetoImageTranslationConditional2016}
Isola, P., Zhu, J.-Y., Zhou, T., and Efros, A.~A.:
Image-to-Image Translation with Conditional Adversarial Networks,
arXiv:1611.07004 [cs], 2016.


\bibitem[{Jeofry et~al.(2017)Jeofry, Ross, Corr, Li, Gogineni, and Siegert}]{Jeofry1KmBedTopography2017}
Jeofry, H., Ross, N., Corr, H. F. J., Li, J., Gogineni, P., and Siegert, M. J.: 1-km bed topography digital elevation model (DEM) of the Weddell Sea sector, West Antarctica, \doi{10.5281/zenodo.1035488}, 2017.

\bibitem[{{Jolicoeur-Martineau}(2018)}]{Jolicoeur-Martineaurelativisticdiscriminatorkey2018}
{Jolicoeur-Martineau}, A.:
The Relativistic Discriminator: A Key Element Missing from Standard GAN,
arXiv:1807.00734 [cs, stat], 2018.

\bibitem[{Jordan et~al.(2010)Jordan, Ferraccioli, Corr, Graham, Armadillo, and Bozzo}]{JordanHypothesismegaoutburstflooding2010}
Jordan, T.~A., Ferraccioli, F., Corr, H., Graham, A., Armadillo, E., and Bozzo, E.:
Hypothesis for Mega-Outburst Flooding from a Palaeo-Subglacial Lake beneath the East Antarctic Ice Sheet: Antarctic Palaeo-Outburst Floods and Subglacial Lake,
Terra Nova,
22, 283--289, \doi{10.1111/j.1365-3121.2010.00944.x}, 2010.

\bibitem[{Joughin et~al.(2009)Joughin, Tulaczyk, Bamber, Blankenship, Holt, Scambos, and Vaughan}]{JoughinBasalconditionsPine2009}
Joughin, I., Tulaczyk, S., Bamber, J.~L., Blankenship, D., Holt, J.~W., Scambos, T., and Vaughan, D.~G.:
Basal Conditions for Pine Island and Thwaites Glaciers, West Antarctica, Determined Using Satellite and Airborne Data,
J. Glaciol.,
55, 245--257, \doi{10.3189/002214309788608705}, 2009.


\bibitem[{Kern et~al.(2020)Kern, Cullen, Berruti, Bouffard, Casal, Drinkwater, Gabriele, Lecuyot, Ludwig, Midthassel, Navas~Traver, Parrinello, Ressler, Andersson, {Martin-Puig}, Andersen, Bartsch, Farrell, Fleury, Gascoin, Guillot, Humbert, Rinne, Shepherd, {van den Broeke}, and Yackel}]{KernCopernicusPolarIce2020}
Kern, M., Cullen, R., Berruti, B., Bouffard, J., Casal, T., Drinkwater, M. R., Gabriele, A., Lecuyot, A., Ludwig, M., Midthassel, R., Navas Traver, I., Parrinello, T., Ressler, G., Andersson, E., Martin-Puig, C., Andersen, O., Bartsch, A., Farrell, S., Fleury, S., Gascoin, S., Guillot, A., Humbert, A., Rinne, E., Shepherd, A., van den Broeke, M. R., and Yackel, J.: The Copernicus Polar Ice and Snow Topography Altimeter (CRISTAL) high-priority candidate mission, The Cryosphere, 14, 2235--2251, \doi{10.5194/tc-14-2235-2020}, 2020.

\bibitem[{King(2011)}]{KingIcestreamnot2011}
King, E. C.: Ice stream or not? Radio-echo sounding of Carlson Inlet, West Antarctica, The Cryosphere, 5, 907--916, \doi{10.5194/tc-5-907-2011}, 2011.

\bibitem[{King et~al.(2016)King, Pritchard, and Smith}]{KingSubglaciallandformsRutford2016}
King, E. C., Pritchard, H. D., and Smith, A. M.: Subglacial landforms beneath Rutford Ice Stream, Antarctica: detailed bed topography from ice-penetrating radar, Earth Syst. Sci. Data, 8, 151--158, \doi{10.5194/essd-8-151-2016}, 2016.

\bibitem[{Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and Hinton}]{KrizhevskyImageNetClassificationDeep2012}
Krizhevsky, A., Sutskever, I., and Hinton, G. E.: ImageNet Classification with Deep Convolutional Neural Networks, in: Advances in Neural Information Processing Systems 25, edited by: Pereira, F., Burges, C. J. C., Bottou, L., and Weinberger, K. Q., Curran Associates, Inc., Lake Tahoe, Nevada, 1097--1105, 2012.

\bibitem[{{Kyrke-Smith} et~al.(2018){Kyrke-Smith}, Gudmundsson, and Farrell}]{Kyrke-SmithRelevanceDetailBasal2018}
Kyrke-Smith, T. M., Gudmundsson, G. H., and Farrell, P. E.: Relevance of Detail in Basal Topography for Basal Slipperiness Inversions: A Case Study on Pine Island Glacier, Antarctica, Front. Earth Sci., 6, 33, \doi{10.3389/feart.2018.00033}, 2018.


\bibitem[{Le~Brocq et~al.(2010)Le~Brocq, Payne, and Vieli}]{LeBrocqimprovedAntarcticdataset2010}
Le Brocq, A. M., Payne, A. J., and Vieli, A.: An improved Antarctic dataset for high resolution numerical ice sheet models (ALBMAP v1), Earth Syst. Sci. Data, 2, 247--260, \doi{10.5194/essd-2-247-2010}, 2010.

\bibitem[{LeCun et~al.(1989)LeCun, Boser, Denker, Henderson, Howard, Hubbard, and Jackel}]{LeCunBackpropagationAppliedHandwritten1989}
LeCun, Y., Boser, B., Denker, J.~S., Henderson, D., Howard, R.~E., Hubbard, W., and Jackel, L.~D.:
Backpropagation Applied to Handwritten Zip Code Recognition,
Neural Comput.,
1, 541--551, \doi{10.1162/neco.1989.1.4.541}, 1989.

\bibitem[{Lecun et~al.(1998)Lecun, Bottou, Bengio, and Haffner}]{LecunGradientbasedlearningapplied1998}
Lecun, Y., Bottou, L., Bengio, Y., and Haffner, P.:
Gradient-Based Learning Applied to Document Recognition,
P. IEEE,
86, 2278--2324, \doi{10.1109/5.726791}, 1998.

\bibitem[{LeCun et~al.(2015)LeCun, Bengio, and Hinton}]{LeCunDeeplearning2015}
LeCun, Y., Bengio, Y., and Hinton, G.:
Deep Learning,
Nature,
521, 436--444, \doi{10.1038/nature14539}, 2015.

\bibitem[{Ledig et~al.(2017)Ledig, Theis, Huszar, Caballero, Cunningham, Acosta, Aitken, Tejani, Totz, Wang, and Shi}]{LedigPhotoRealisticSingleImage2017}
Ledig, C., Theis, L., Huszar, F., Caballero, J., Cunningham, A., Acosta, A., Aitken, A., Tejani, A., Totz, J., Wang, Z., and Shi, W.: Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network, in: 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), IEEE, Honolulu, Hawaii, 105--114, \doi{10.1109/CVPR.2017.19}, 21--26~July~2017.

\bibitem[Leong and Horgan(2020)]{LeongHorgan2020b}
Leong, W. J. and Horgan, H. J.: DeepBedMap (Version v1.0.0), Zenodo, \doi{10.5281/zenodo.3752614}, 2020.

\bibitem[{Li et~al.(2018)Li, Jamieson, DeSalvo, Rostamizadeh, and Talwalkar}]{LiHyperbandNovelBanditBased2018}
Li, L., Jamieson, K., DeSalvo, G., Rostamizadeh, A., and Talwalkar, A.:
Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization,
arXiv:1603.06560 [cs, stat], 2018.

\bibitem[{Lim et~al.(2017)Lim, Son, Kim, Nah, and Lee}]{LimEnhancedDeepResidual2017}
Lim, B., Son, S., Kim, H., Nah, S., and Lee, K.~M.:
Enhanced Deep Residual Networks for Single Image Super-Resolution,
arXiv:1707.02921 [cs], 2017.

\bibitem[{Liu et~al.(2018)Liu, Wang, and Liu}]{LiuPSGANGenerativeAdversarial2018}
Liu, X., Wang, Y., and Liu, Q.:
PSGAN: A Generative Adversarial Network for Remote Sensing Image Pan-Sharpening,
arXiv:1805.03371 [cs], 2018.

\bibitem[{Lythe and Vaughan(2001)}]{LytheBEDMAPnewice2001}
Lythe, M.~B. and Vaughan, D.~G.: BEDMAP:
A New Ice Thickness and Subglacial Topographic Model of Antarctica,
J. Geophys. Res.-Sol. Ea.,
106, 11335--11351, \doi{10.1029/2000JB900449}, 2001.


\bibitem[{Maas et~al.(2013)Maas, Hannun, and Ng}]{MaasRectifiernonlinearitiesimprove2013}
Maas, A. L., Hannun, A. Y., and Ng, A. Y.: Rectifier nonlinearities improve neural network acoustic models, in ICML Workshop on Deep Learning for Audio, Speech, and Language Processing, Atlanta, Georgia, USA, 16~June~2013.

\bibitem[{Markus et~al.(2017)Markus, Neumann, Martino, Abdalati, Brunt, Csatho, Farrell, Fricker, Gardner, Harding, Jasinski, Kwok, Magruder, Lubin, Luthcke, Morison, Nelson, Neuenschwander, Palm, Popescu, Shum, Schutz, Smith, Yang, and Zwally}]{MarkusIceCloudland2017}
Markus, T., Neumann, T., Martino, A., Abdalati, W., Brunt, K., Csatho, B., Farrell, S., Fricker, H., Gardner, A., Harding, D., Jasinski, M., Kwok, R., Magruder, L., Lubin, D., Luthcke, S., Morison, J., Nelson, R., Neuenschwander, A., Palm, S., Popescu, S., Shum, C., Schutz, B.~E., Smith, B., Yang, Y., and Zwally, J.:
The Ice, Cloud, and Land Elevation Satellite-2 (ICESat-2): Science Requirements, Concept, and Implementation,
Remote Sens. Environ.,
190, 260--273, \doi{10.1016/j.rse.2016.12.029}, 2017.

\bibitem[{Masi et~al.(2016)Masi, Cozzolino, Verdoliva, and Scarpa}]{MasiPansharpeningConvolutionalNeural2016}
Masi, G., Cozzolino, D., Verdoliva, L., and Scarpa, G.:
Pansharpening by Convolutional Neural Networks,
Remote Sens.-Basel,
8, 594, \doi{10.3390/rs8070594}, 2016.

\bibitem[{Monnier and Zhu(2018)}]{MonnierInferencebedtopography2018}
Monnier, J. and Zhu, J.: Inference of the bed topography in poorly flew over ice-sheets areas from surface data and a reduced uncertainty flow model, HAL Archives Ouvertes, available at: \url{https://hal.archives-ouvertes.fr/hal-01926620} (last access: 7~March~2019), 2018.

\bibitem[{Morlighem(2019)}]{MorlighemMEaSUREsBedMachineAntarctica2019}
Morlighem, M.: MEaSUREs BedMachine Antarctica, Version 1, Boulder, Colorado, USA. NASA National Snow and Ice Data Center Distributed Active Archive Center, \doi{10.5067/C2GFER6PTOS4}, 2019.

\bibitem[{Morlighem et~al.(2011)Morlighem, Rignot, Seroussi, Larour, Ben~Dhia, and Aubry}]{Morlighemmassconservationapproach2011}
Morlighem, M., Rignot, E., Seroussi, H., Larour, E., Ben~Dhia, H., and Aubry, D.:
A Mass Conservation Approach for Mapping Glacier Ice Thickness: BALANCE THICKNESS,
Geophys. Res. Lett.,
38, \doi{10.1029/2011GL048659}, 2011.

\bibitem[{Morlighem et~al.(2017)Morlighem, Williams, Rignot, An, Arndt, Bamber, Catania, Chauch{\'e}, Dowdeswell, Dorschel, Fenty, Hogan, Howat, Hubbard, Jakobsson, Jordan, Kjeldsen, Millan, Mayer, Mouginot, No{\"e}l, O'Cofaigh, Palmer, Rysgaard, Seroussi, Siegert, Slabon, Straneo, {van den Broeke}, Weinrebe, Wood, and Zinglersen}]{MorlighemBedMachinev3Complete2017}
Morlighem, M., Williams, C.~N., Rignot, E., An, L., Arndt, J.~E., Bamber, J.~L., Catania, G., Chauch{\'e}, N., Dowdeswell, J.~A., Dorschel, B., Fenty, I., Hogan, K., Howat, I., Hubbard, A., Jakobsson, M., Jordan, T.~M., Kjeldsen, K.~K., Millan, R., Mayer, L., Mouginot, J., No{\"e}l, B. P.~Y., O'Cofaigh, C., Palmer, S., Rysgaard, S., Seroussi, H., Siegert, M.~J., Slabon, P., Straneo, F., {van den Broeke}, M.~R., Weinrebe, W., Wood, M., and Zinglersen, K.~B.:
BedMachine v3: Complete Bed Topography and Ocean Bathymetry Mapping of Greenland From Multibeam Echo Sounding Combined With Mass Conservation,
Geophys. Res. Lett.,
44, 11051--11061, \doi{10.1002/2017GL074954}, 2017.

\bibitem[{Morlighem et~al.(2019)Morlighem, Rignot, Binder, Blankenship, Drews, Eagles, Eisen, Ferraccioli, Forsberg, Fretwell, Goel, Greenbaum, Gudmundsson, Guo, Helm, Hofstede, Howat, Humbert, Jokat, Karlsson, Lee, Matsuoka, Millan, Mouginot, Paden, Pattyn, Roberts, Rosier, Ruppel, Seroussi, Smith, Steinhage, Sun, van~den Broeke, van Ommen, van Wessem, and Young}]{MorlighemDeepglacialtroughs2019}
Morlighem, M., Rignot, E., Binder, T., Blankenship, D., Drews, R., Eagles, G., Eisen, O., Ferraccioli, F., Forsberg, R., Fretwell, P., Goel, V., Greenbaum, J. S., Gudmundsson, H., Guo, J., Helm, V., Hofstede, C., Howat, I., Humbert, A., Jokat, W., Karlsson, N. B., Lee, W. S., Matsuoka, K., Millan, R., Mouginot, J., Paden, J., Pattyn, F., Roberts, J., Rosier, S., Ruppel, A., Seroussi, H., Smith, E. C., Steinhage, D., Sun, B., Broeke, M. R. van den, Ommen, T. D. van, Wessem, M., and van and Young, D. A.: Deep glacial troughs and stabilizing ridges unveiled beneath the margins of the Antarctic ice sheet, Nat. Geosci., 13, 132--137, \doi{10.1038/s41561-019-0510-8}, 2019.

\bibitem[{Mouginot et~al.(2017)Mouginot, Scheuchl, and Rignot}]{MouginotMEaSURESAntarcticBoundaries2017}
Mouginot, J., Scheuchl, B., and Rignot, E.: MEaSUREs Antarctic Boundaries for IPY 2007--2009 from Satellite Radar, Version 2. Boulder, Colorado, USA, NASA National Snow and Ice Data Center Distributed Active Archive Center, \doi{10.5067/AXE4121732AD}, 2017.

\bibitem[{Mouginot et~al.(2019{\natexlab{a}})Mouginot, Rignot, and Scheuchl}]{MouginotContinentwideinterferometric2019}
Mouginot, J., Rignot, E., and Scheuchl, B.:
Continent-Wide, Interferometric SAR Phase, Mapping of Antarctic Ice Velocity,
Geophys. Res. Lett.,
46, 9710--9718, \doi{10.1029/2019GL083826}, 2019{\natexlab{a}}.

\bibitem[{Mouginot et~al.(2019{\natexlab{b}})Mouginot, Rignot, and Scheuchl}]{MouginotMEaSUREsPhaseMap2019}
Mouginot, J., Rignot, E., and Scheuchl, B.: MEaSUREs Phase-Based Antarctica Ice Velocity Map, Version 1. Boulder, Colorado, USA, NASA National Snow and Ice Data Center Distributed Active Archive Center, \doi{10.5067/PZ3NJ5RXRH10}, 2019b.


\bibitem[{Nasrollahi and Moeslund(2014)}]{NasrollahiSuperresolutioncomprehensivesurvey2014}
Nasrollahi, K. and Moeslund, T.~B.:
Super-Resolution: A Comprehensive Survey,
Mach. Vision Appl.,
25, 1423--1468, \doi{10.1007/s00138-014-0623-4}, 2014.

\bibitem[{Nias et~al.(2016)Nias, Cornford, and Payne}]{NiasContrastingmodelledsensitivity2016}
Nias, I.~J., Cornford, S.~L., and Payne, A.~J.:
Contrasting the Modelled Sensitivity of the Amundsen Sea Embayment Ice Streams,
J. Glaciol.,
62, 552--562, \doi{10.1017/jog.2016.40}, 2016.


\bibitem[{Park et~al.(2019)Park, Liu, Wang, and Zhu}]{ParkSemanticImageSynthesis2019}
Park, T., Liu, M.-Y., Wang, T.-C., and Zhu, J.-Y.:
Semantic Image Synthesis with Spatially-Adaptive Normalization,
arXiv:1903.07291 [cs], 2019.


\bibitem[{Raymond and Gudmundsson(2005)}]{Raymondrelationshipsurfacebasal2005}
Raymond, M. J. and Gudmundsson, G. H.: On the relationship between surface and basal properties on glaciers, ice sheets, and ice streams, J. Geophys. Res.-Sol. Ea., 110, B08411, \doi{10.1029/2005JB003681}, 2005.

\bibitem[{Rignot et~al.(2011)Rignot, Mouginot, and Scheuchl}]{RignotAntarcticgroundingline2011}
Rignot, E., Mouginot, J., and Scheuchl, B.:
Antarctic Grounding Line Mapping from Differential Satellite Radar Interferometry: Grounding Line of Antarctica,
Geophys. Res. Lett.,
38, \doi{10.1029/2011GL047109}, 2011.

\bibitem[{Rippin et~al.(2014)Rippin, Bingham, Jordan, Wright, Ross, Corr, Ferraccioli, Le~Brocq, Rose, and Siegert}]{RippinBasalroughnessInstitute2014}
Rippin, D., Bingham, R., Jordan, T., Wright, A., Ross, N., Corr, H., Ferraccioli, F., Le~Brocq, A., Rose, K., and Siegert, M.:
Basal Roughness of the Institute and M\"oller Ice Streams, West Antarctica: Process Determination and Landscape Interpretation,
Geomorphology,
214, 139--147, \doi{10.1016/j.geomorph.2014.01.021}, 2014.

\bibitem[{Robin et~al.(1970)Robin, Swithinbank, and Smith}]{RobinRadioechoexploration1970}
Robin, G. D.~Q., Swithinbank, C., and Smith, B.:
Radio Echo Exploration of the Antarctic Ice Sheet,
in: International Symposium on Antarctic Glaciological Exploration (ISAGE),
edited by: Gow, A., Keeler, C., Langway, C., and Weeks, W.,
no.~86 in IASH Publication,
International Association of Scientific Hydrology, Hanover, New Hampshire, USA, 97--115, 1970.

\bibitem[{Rumelhart et~al.(1986)Rumelhart, Hinton, and Williams}]{RumelhartLearningrepresentationsbackpropagating1986}
Rumelhart, D.~E., Hinton, G.~E., and Williams, R.~J.:
Learning Representations by Back-Propagating Errors,
Nature,
323, 533--536, \doi{10.1038/323533a0}, 1986.


\bibitem[{Scambos(2014)}]{ScambosSnowMegadune2014}
Scambos, T.:
Snow Megadune,
Springer New York, New York, NY, \doi{10.1007/978-1-4614-9213-9_620-1}, 1--3, 2014.

\bibitem[{Scarpa et~al.(2018)Scarpa, Vitale, and Cozzolino}]{ScarpaTargetAdaptiveCNNBasedPansharpening2018}
Scarpa, G., Vitale, S., and Cozzolino, D.:
Target-Adaptive CNN-Based Pansharpening,
IEEE T. Geosci. Remote,
56, 5443--5457, \doi{10.1109/TGRS.2018.2817393}, 2018.

\bibitem[{Sergienko and Hindmarsh(2013)}]{SergienkoRegularPatternsFrictional2013}
Sergienko, O.~V. and Hindmarsh, R. C.~A.:
Regular Patterns in Frictional Resistance of Ice-Stream Beds Seen by Surface Data Inversion,
Science,
342, 1086--1089, \doi{10.1126/science.1243903}, 2013.

\bibitem[{Shi et~al.(2010)Shi, Allen, Ledford, {Rodriguez-Morales}, Blake, Panzer, Prokopiack, Leuschen, and Gogineni}]{ShiMultichannelCoherentRadar2010}
Shi, L., Allen, C. T., Ledford, J. R., Rodriguez-Morales, F., Blake, W. A., Panzer, B. G., Prokopiack, S. C., Leuschen, C. J., and Gogineni, S.: Multichannel Coherent Radar Depth Sounder for NASA Operation Ice Bridge, in 2010 IEEE International Geoscience and Remote Sensing Symposium, pp. 1729--1732, IEEE, Honolulu, HI, USA, \doi{10.1109/IGARSS.2010.5649518}, 25--30~July~2010.

\bibitem[{Siegert et~al.(2004)Siegert, Taylor, Payne, and Hubbard}]{SiegertMacroscalebedroughness2004}
Siegert, M.~J., Taylor, J., Payne, A.~J., and Hubbard, B.:
Macro-Scale Bed Roughness of the Siple Coast Ice Streams in West Antarctica,
Earth Surf. Proc. Land.,
29, 1591--1596, \doi{10.1002/esp.1100}, 2004.

\bibitem[{Simonyan and Zisserman(2014)}]{SimonyanVeryDeepConvolutional2014}
Simonyan, K. and Zisserman, A.:
Very Deep Convolutional Networks for Large-Scale Image Recognition,
arXiv:1409.1556 [cs], 2014.

\bibitem[{Solheim and Pfirman(1985)}]{SolheimSeafloormorphologyoutside1985}
Solheim, A. and Pfirman, S. L.: Sea-floor morphology outside a grounded, surging glacier; Br{\aa}svellbreen, Svalbard, Mar. Geol., 65, 127--143, \doi{10.1016/0025-3227(85)90050-7}, 1985.


\bibitem[{Tokui et~al.(2019)Tokui, Yamazaki~Vincent, Okuta, Akiba, Niitani, Ogawa, Saito, Suzuki, Uenishi, and Vogel}]{TokuiChainerDeepLearning2019}
Tokui, S., Yamazaki Vincent, H., Okuta, R., Akiba, T., Niitani, Y., Ogawa, T., Saito, S., Suzuki, S., Uenishi, K., and Vogel, B.: Chainer: A Deep Learning Framework for Accelerating the Research Cycle, in: Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining  -- KDD '19, ACM Press, Anchorage, AK, USA, 2002--2011, \doi{10.1145/3292500.3330756}, 4--8~August~2019.

\bibitem[{Tsai and Huang(1984)}]{TsaiMultiframeimagerestoration1984}
Tsai, R. and Huang, T.~S.:
Multiframe Image Restoration and Registration,
in: Advance Computer Visual and Image Processing, vol.~1,
edited by: Huang, T.~S.,
JAI Press, Greenwich, CT, 317--339, 1984.


\bibitem[{{van Pelt} et~al.(2013){van Pelt}, Oerlemans, Reijmer, Pettersson, Pohjola, Isaksson, and Divine}]{vanPeltiterativeinversemethod2013}
van Pelt, W. J. J., Oerlemans, J., Reijmer, C. H., Pettersson, R., Pohjola, V. A., Isaksson, E., and Divine, D.: An iterative inverse method to estimate basal topography and initialize ice flow models, The Cryosphere, 7, 987--1006, \doi{10.5194/tc-7-987-2013}, 2013.


\bibitem[{Wang et~al.(2019)Wang, Yu, Wu, Gu, Liu, Dong, Qiao, and Loy}]{WangESRGANEnhancedSuperResolution2019}
Wang, X., Yu, K., Wu, S., Gu, J., Liu, Y., Dong, C., Qiao, Y., and Loy, C.~C.:
ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks,
in: Computer Vision~-- ECCV 2018 Workshops, vol. 11133,
edited by: Leal-Taix{\'e}, L. and Roth, S.,
Springer International Publishing, {Cham}, \doi{10.1007/978-3-030-11021-5_5}, 63--79, 2019.

\bibitem[{Wang et~al.(2004)Wang, Bovik, Sheikh, and Simoncelli}]{WangImageQualityAssessment2004}
Wang, Z., Bovik, A., Sheikh, H., and Simoncelli, E.:
Image Quality Assessment: From Error Visibility to Structural Similarity,
IEEE T. Image Process.,
13, 600--612, \doi{10.1109/TIP.2003.819861}, 2004.

\hack{\newpage}

\bibitem[{Wessel et~al.(2019)Wessel, Luis, Uieda, Scharroo, Wobbe, Smith, and Tian}]{WesselGenericMappingTools2019}
Wessel, P., Luis, J., Uieda, L., Scharroo, R., Wobbe, F., Smith, W., and Tian, D.:
The Generic Mapping Tools Version 6,
Geochem. Geophy. Geosy.,
20, 5556--5564, \doi{10.1029/2019GC008515}, 2019.


\bibitem[{Xu et~al.(2015)Xu, Wang, Chen, Xiong, Ding, and Hou}]{XuNonlocalsimilaritybased2015}
Xu, Z., Wang, X., Chen, Z., Xiong, D., Ding, M., and Hou, W.:
Nonlocal Similarity Based DEM Super Resolution,
ISPRS J. Photogramm.,
110, 48--54, \doi{10.1016/j.isprsjprs.2015.10.009}, 2015.


\bibitem[{Yang et~al.(2017)Yang, Fu, Hu, Huang, Ding, and Paisley}]{YangPanNetDeepNetwork2017}
Yang, J., Fu, X., Hu, Y., Huang, Y., Ding, X., and Paisley, J.: PanNet: A Deep Network Architecture for Pan-Sharpening, in: 2017 IEEE International Conference on Computer Vision (ICCV), IEEE, Venice, Italy, 1753--1761, \doi{10.1109/ICCV.2017.193}, 22--29~October~2017.

\bibitem[{Yang et~al.(2019)Yang, Zhang, Tian, Wang, Xue, and Liao}]{YangDeepLearningSingle2019}
Yang, W., Zhang, X., Tian, Y., Wang, W., Xue, J.-H., and Liao, Q.:
Deep Learning for Single Image Super-Resolution: A Brief Review,
IEEE T. Multimedia,
21, 3106--3121, \doi{10.1109/TMM.2019.2919431}, 2019.

\end{thebibliography}

\end{document}

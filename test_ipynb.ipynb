{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioural Driven Development Testing for Jupyter Notebooks\n",
    "\n",
    "Handy way to process the run unit tests (via doctest) and integration tests (via behave) in jupyter notebooks (.ipynb) containing Python functions.\n",
    "The script will convert an .ipynb to a string format (basically a .py file), loads them as modules, and runs the tests on them.\n",
    "To run it in the console, do:\n",
    "\n",
    "    python -m pytest --verbose --disable-warnings --nbval test_ipynb.ipynb\n",
    "\n",
    "The script should tell you which ipynb file's doctests has failed (e.g. srgan_train.ipynb).\n",
    "You can then open up this very jupyter notebook to debug and inspect the situation further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from features.environment import _load_ipynb_modules\n",
    "import behave.__main__\n",
    "\n",
    "import doctest\n",
    "import os\n",
    "import sys\n",
    "\n",
    "def _unit_test_ipynb(path: str):\n",
    "    \"\"\"\n",
    "    Unit tests on loaded modules from a .ipynb file.\n",
    "    Uses doctest.\n",
    "    \"\"\"\n",
    "    assert path.endswith(\".ipynb\")\n",
    "\n",
    "    module = _load_ipynb_modules(ipynb_path=path)\n",
    "    num_failures, num_attempted = doctest.testmod(m=module, verbose=True)\n",
    "    if num_failures > 0:\n",
    "        sys.exit(num_failures)\n",
    "\n",
    "def _integration_test_ipynb(path: str, summary: bool = False):\n",
    "    \"\"\"\n",
    "    Integration tests on various feature behaviours inside a .feature file.\n",
    "    Uses behave.\n",
    "    \"\"\"\n",
    "    assert os.path.exists(path=path)\n",
    "    assert path.endswith(\".feature\")\n",
    "\n",
    "    if summary == False:\n",
    "        args = f\"--tags ~@skip --no-summary {path}\"\n",
    "    elif summary == True:\n",
    "        args = f\"--tags ~@skip {path}\"\n",
    "\n",
    "    num_failures = behave.__main__.main(args=args)\n",
    "    if num_failures > 0:\n",
    "        sys.exit(num_failures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit tests\n",
    "\n",
    "Uses [doctest](https://en.wikipedia.org/wiki/Doctest).\n",
    "Small tests for each individual function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying:\n",
      "    os.makedirs(name=\"/tmp/highres\", exist_ok=True)\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    download_to_path(path=\"/tmp/highres/2011_Antarctica_TO.csv\",\n",
      "                     url=\"https://data.cresis.ku.edu/data/rds/2011_Antarctica_TO/csv_good/2011_Antarctica_TO.csv\")\n",
      "Expecting:\n",
      "    <Response [200]>\n",
      "ok\n",
      "Trying:\n",
      "    _ = shutil.copy(src=\"highres/20xx_Antarctica_TO.json\", dst=\"/tmp/highres\")\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    df = ascii_to_xyz(pipeline_file=\"/tmp/highres/20xx_Antarctica_TO.json\")\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    df.head(2)\n",
      "Expecting:\n",
      "                   x              y         z\n",
      "    0  345580.826265  345580.826265 -377.2340\n",
      "    1  345593.322948  345593.322948 -376.6332\n",
      "ok\n",
      "Trying:\n",
      "    shutil.rmtree(path=\"/tmp/highres\")\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    download_to_path(path=\"highres/Data_20171204_02.csv\",\n",
      "                     url=\"https://data.cresis.ku.edu/data/rds/2017_Antarctica_Basler/csv_good/Data_20171204_02.csv\")\n",
      "Expecting:\n",
      "    <Response [200]>\n",
      "ok\n",
      "Trying:\n",
      "    check_sha256(\"highres/Data_20171204_02.csv\")\n",
      "Expecting:\n",
      "    '53cef7a0d28ff92b30367514f27e888efbc32b1bda929981b371d2e00d4c671b'\n",
      "ok\n",
      "Trying:\n",
      "    os.remove(path=\"highres/Data_20171204_02.csv\")\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    download_to_path(path=\"highres/Data_20171204_02.csv\",\n",
      "                     url=\"https://data.cresis.ku.edu/data/rds/2017_Antarctica_Basler/csv_good/Data_20171204_02.csv\")\n",
      "Expecting:\n",
      "    <Response [200]>\n",
      "ok\n",
      "Trying:\n",
      "    open(\"highres/Data_20171204_02.csv\").readlines()\n",
      "Expecting:\n",
      "    ['LAT,LON,UTCTIMESOD,THICK,ELEVATION,FRAME,SURFACE,BOTTOM,QUALITY\\n']\n",
      "ok\n",
      "Trying:\n",
      "    os.remove(path=\"highres/Data_20171204_02.csv\")\n",
      "Expecting nothing\n",
      "ok\n",
      "4 items had no tests:\n",
      "    data_prep\n",
      "    data_prep.get_window_bounds\n",
      "    data_prep.parse_datalist\n",
      "    data_prep.selective_tile\n",
      "3 items passed all tests:\n",
      "   6 tests in data_prep.ascii_to_xyz\n",
      "   3 tests in data_prep.check_sha256\n",
      "   3 tests in data_prep.download_to_path\n",
      "12 tests in 7 items.\n",
      "12 passed and 0 failed.\n",
      "Test passed.\n"
     ]
    }
   ],
   "source": [
    "_unit_test_ipynb(path=\"data_prep.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying:\n",
      "    metrics = {\"generator_network\": 'mse', \"discriminator_network\": 'accuracy'}\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    models = compile_srgan_model(g_network=generator_network(), d_network=discriminator_network(), metrics=metrics)\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    models['discriminator_model'].trainable\n",
      "Expecting:\n",
      "    True\n",
      "ok\n",
      "Trying:\n",
      "    models['srgan_model'].get_layer(name='generator_network').trainable\n",
      "Expecting:\n",
      "    True\n",
      "ok\n",
      "Trying:\n",
      "    models['srgan_model'].get_layer(name='discriminator_network').trainable\n",
      "Expecting:\n",
      "    False\n",
      "ok\n",
      "Trying:\n",
      "    models['srgan_model'].count_params()\n",
      "Expecting:\n",
      "    8571362\n",
      "ok\n",
      "Trying:\n",
      "    discriminator_network().input_shape\n",
      "Expecting:\n",
      "    (None, 32, 32, 1)\n",
      "ok\n",
      "Trying:\n",
      "    discriminator_network().output_shape\n",
      "Expecting:\n",
      "    (None, 1)\n",
      "ok\n",
      "Trying:\n",
      "    discriminator_network().count_params()\n",
      "Expecting:\n",
      "    6828033\n",
      "ok\n",
      "Trying:\n",
      "    generator_network().input_shape\n",
      "Expecting:\n",
      "    [(None, 8, 8, 1), (None, 40, 40, 1), (None, 16, 16, 1)]\n",
      "ok\n",
      "Trying:\n",
      "    generator_network().output_shape\n",
      "Expecting:\n",
      "    (None, 32, 32, 1)\n",
      "ok\n",
      "Trying:\n",
      "    generator_network().count_params()\n",
      "Expecting:\n",
      "    1743329\n",
      "ok\n",
      "Trying:\n",
      "    K.eval(psnr(y_true=np.ones(shape=(3,3)), y_pred=np.full(shape=(3,3), fill_value=2)))\n",
      "Expecting:\n",
      "    array([221.80709678, 221.80709678, 221.80709678])\n",
      "ok\n",
      "Trying:\n",
      "    generator_inputs = [np.random.RandomState(seed=42).rand(32,s,s,1) for s in [8,40,16]]\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    groundtruth_images = np.random.RandomState(seed=42).rand(32,32,32,1)\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    models = compile_srgan_model(g_network=generator_network(), d_network=discriminator_network())\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    d_weight0 = K.eval(models['discriminator_model'].weights[0][0,0,0,0])\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    _, _ = train_discriminator(models=models, generator_inputs=generator_inputs, groundtruth_images=groundtruth_images)\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    d_weight1 = K.eval(models['discriminator_model'].weights[0][0,0,0,0])\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    d_weight0 != d_weight1  #check that discriminator training has occurred (i.e. weights changed)\n",
      "Expecting:\n",
      "    True\n",
      "ok\n",
      "Trying:\n",
      "    generator_inputs = [np.random.RandomState(seed=42).rand(32,s,s,1) for s in [8,40,16]]\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    groundtruth_images = np.random.RandomState(seed=42).rand(32,32,32,1)\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    models = compile_srgan_model(g_network=generator_network(), d_network=discriminator_network())\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    g_weight0 = K.eval(models['generator_model'].weights[0][0,0,0,0])\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    _, _ = train_generator(models=models, generator_inputs=generator_inputs, groundtruth_images=groundtruth_images)\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    g_weight1 = K.eval(models['generator_model'].weights[0][0,0,0,0])\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    g_weight0 != g_weight1  #check that generator training has occurred (i.e. weights changed)\n",
      "Expecting:\n",
      "    True\n",
      "ok\n",
      "1 items had no tests:\n",
      "    srgan_train\n",
      "6 items passed all tests:\n",
      "   6 tests in srgan_train.compile_srgan_model\n",
      "   3 tests in srgan_train.discriminator_network\n",
      "   3 tests in srgan_train.generator_network\n",
      "   1 tests in srgan_train.psnr\n",
      "   7 tests in srgan_train.train_discriminator\n",
      "   7 tests in srgan_train.train_generator\n",
      "27 tests in 7 items.\n",
      "27 passed and 0 failed.\n",
      "Test passed.\n"
     ]
    }
   ],
   "source": [
    "_unit_test_ipynb(path=\"srgan_train.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration tests\n",
    "\n",
    "Uses [behave](https://github.com/behave/behave).\n",
    "Medium sized tests which checks that components work together properly.\n",
    "Ensures that the behaviour of features (made up of units) is sound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@fixture.data_prep\n",
      "Feature: Data preparation # features/data_prep.feature:3\n",
      "  In order to have reproducible data inputs for everyone\n",
      "  As a data scientist,\n",
      "  We want to share cryptographically secured pieces of the datasets\n",
      "  Scenario Outline: Download and check data -- @1.1 Files to download and check                                                          # features/data_prep.feature:15\n",
      "    Given this https://data.cresis.ku.edu/data/rds/2017_Antarctica_Basler/csv_good/Data_20171204_02.csv link to a file hosted on the web # features/steps/data_prep.py:6\n",
      "    When we download it to highres/Data_20171204_02.csv                                                                                  # features/steps/data_prep.py:11\n",
      "    Then the local file should have this 53cef7a0d28ff92b30367514f27e888efbc32b1bda929981b371d2e00d4c671b checksum                       # features/steps/data_prep.py:17\n",
      "\n",
      "  Scenario Outline: Download and check data -- @1.2 Files to download and check                                                                                                                                                                                                                              # features/data_prep.feature:16\n",
      "    Given this http://ramadda.nerc-bas.ac.uk/repository/entry/get/Polar%20Data%20Centre/DOI/Rutford%20Ice%20Stream%20bed%20elevation%20DEM%20from%20radar%20data/bed_WGS84_grid.txt?entryid=synth%3A54757cbe-0b13-4385-8b31-4dfaa1dab55e%3AL2JlZF9XR1M4NF9ncmlkLnR4dA%3D%3D link to a file hosted on the web # features/steps/data_prep.py:6\n",
      "    When we download it to highres/bed_WGS84_grid.txt                                                                                                                                                                                                                                                        # features/steps/data_prep.py:11\n",
      "    Then the local file should have this 7396e56cda5adb82cecb01f0b3e01294ed0aa6489a9629f3f7e8858ea6cb91cf checksum                                                                                                                                                                                           # features/steps/data_prep.py:17\n",
      "\n",
      "  @skip @wip\n",
      "  Scenario Outline: Grid single dataset -- @1.1 Inputs to process to an output  # features/data_prep.feature:26\n",
      "    Given a high resolution dataset bed_WGS84_grid.txt                          # None\n",
      "    When we process it through bed_WGS84_grid.json                              # None\n",
      "    Then a raster grid is returned bed_WGS84_grid.tif                           # None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_integration_test_ipynb(path=\"features/data_prep.feature\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepbedmap",
   "language": "python",
   "name": "deepbedmap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

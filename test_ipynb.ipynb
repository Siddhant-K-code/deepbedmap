{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doctests for jupyter notebook\n",
    "\n",
    "Handy way to process the doctests in jupyter notebooks (.ipynb) containing Python functions.\n",
    "The script converts an .ipynb to a string format (basically a .py file), loads them as modules, and runs doctest on them.\n",
    "To run it in the console, do:\n",
    "\n",
    "    python -m pytest --verbose --disable-warnings --nbval test_ipynb.ipynb\n",
    "\n",
    "The script should tell you which ipynb file's doctests has failed (e.g. srgan_train.ipynb).\n",
    "You can then open up this very jupyter notebook to debug and inspect the situation further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import doctest\n",
    "import nbconvert\n",
    "import nbformat\n",
    "import os\n",
    "import sys\n",
    "import types\n",
    "\n",
    "def _doctest_ipynb(path:str):\n",
    "    \"\"\"\n",
    "    First converts .ipynb to a temporary .py file\n",
    "    Then it runs doctest on the temp .py file\n",
    "    \"\"\"\n",
    "    assert(path.endswith('.ipynb'))\n",
    "    basename, _ = os.path.splitext(path)\n",
    "    \n",
    "    #read ipynb file and get the text\n",
    "    with open(path) as ipynb_file:\n",
    "        nb = nbformat.reads(s=ipynb_file.read(), as_version=nbformat.NO_CONVERT)\n",
    "    assert(isinstance(nb, nbformat.notebooknode.NotebookNode))\n",
    "    \n",
    "    #convert the .ipynb text to a string .py format\n",
    "    pyexporter = nbconvert.PythonExporter()\n",
    "    source, meta = pyexporter.from_notebook_node(nb=nb)\n",
    "    assert(isinstance(source, str))\n",
    "    \n",
    "    #parse the .py string to pick out only 'import' and 'def function's\n",
    "    parsed_code = ast.parse(source=source)\n",
    "    for node in parsed_code.body[:]:\n",
    "        if node.__class__ not in [ast.FunctionDef, ast.Import, ast.ImportFrom]:\n",
    "            parsed_code.body.remove(node)\n",
    "    assert(len(parsed_code.body) > 0)\n",
    "    \n",
    "    #import modules from the parsed .py string\n",
    "    module = types.ModuleType(basename)\n",
    "    code = compile(source=parsed_code, filename=f'{basename}.py', mode='exec')\n",
    "    exec(code, module.__dict__)\n",
    "    \n",
    "    num_failures, num_attempted = doctest.testmod(m=module, verbose=True)\n",
    "    if num_failures > 0:\n",
    "        sys.exit(num_failures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying:\n",
      "    download_to_path(path=\"highres/2017_Antarctica_Basler.csv\", url=\"https://data.cresis.ku.edu/data/rds/2017_Antarctica_Basler/csv_good/2017_Antarctica_Basler.csv\").headers['Content-Length']\n",
      "Expecting:\n",
      "    '64'\n",
      "ok\n",
      "3 items had no tests:\n",
      "    data_prep\n",
      "    data_prep.get_window_bounds\n",
      "    data_prep.selective_tile\n",
      "1 items passed all tests:\n",
      "   1 tests in data_prep.download_to_path\n",
      "1 tests in 4 items.\n",
      "1 passed and 0 failed.\n",
      "Test passed.\n"
     ]
    }
   ],
   "source": [
    "_doctest_ipynb('data_prep.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying:\n",
      "    metrics = {\"generator_network\": 'mse', \"discriminator_network\": 'accuracy'}\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    models = compile_srgan_model(g_network=generator_network(), d_network=discriminator_network(), metrics=metrics)\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    models['discriminator_model'].trainable\n",
      "Expecting:\n",
      "    True\n",
      "ok\n",
      "Trying:\n",
      "    models['srgan_model'].get_layer(name='generator_network').trainable\n",
      "Expecting:\n",
      "    True\n",
      "ok\n",
      "Trying:\n",
      "    models['srgan_model'].get_layer(name='discriminator_network').trainable\n",
      "Expecting:\n",
      "    False\n",
      "ok\n",
      "Trying:\n",
      "    models['srgan_model'].count_params()\n",
      "Expecting:\n",
      "    8571362\n",
      "ok\n",
      "Trying:\n",
      "    discriminator_network().input_shape\n",
      "Expecting:\n",
      "    (None, 32, 32, 1)\n",
      "ok\n",
      "Trying:\n",
      "    discriminator_network().output_shape\n",
      "Expecting:\n",
      "    (None, 1)\n",
      "ok\n",
      "Trying:\n",
      "    discriminator_network().count_params()\n",
      "Expecting:\n",
      "    6828033\n",
      "ok\n",
      "Trying:\n",
      "    generator_network().input_shape\n",
      "Expecting:\n",
      "    [(None, 8, 8, 1), (None, 40, 40, 1), (None, 16, 16, 1)]\n",
      "ok\n",
      "Trying:\n",
      "    generator_network().output_shape\n",
      "Expecting:\n",
      "    (None, 32, 32, 1)\n",
      "ok\n",
      "Trying:\n",
      "    generator_network().count_params()\n",
      "Expecting:\n",
      "    1743329\n",
      "ok\n",
      "Trying:\n",
      "    K.eval(psnr(y_true=np.ones(shape=(3,3)), y_pred=np.full(shape=(3,3), fill_value=2)))\n",
      "Expecting:\n",
      "    array([221.80709678, 221.80709678, 221.80709678])\n",
      "ok\n",
      "Trying:\n",
      "    generator_inputs = [np.random.RandomState(seed=42).rand(32,s,s,1) for s in [8,40,16]]\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    groundtruth_images = np.random.RandomState(seed=42).rand(32,32,32,1)\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    models = compile_srgan_model(g_network=generator_network(), d_network=discriminator_network())\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    d_weight0 = K.eval(models['discriminator_model'].weights[0][0,0,0,0])\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    _, _ = train_discriminator(models=models, generator_inputs=generator_inputs, groundtruth_images=groundtruth_images)\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    d_weight1 = K.eval(models['discriminator_model'].weights[0][0,0,0,0])\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    d_weight0 != d_weight1  #check that discriminator training has occurred (i.e. weights changed)\n",
      "Expecting:\n",
      "    True\n",
      "ok\n",
      "Trying:\n",
      "    generator_inputs = [np.random.RandomState(seed=42).rand(32,s,s,1) for s in [8,40,16]]\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    groundtruth_images = np.random.RandomState(seed=42).rand(32,32,32,1)\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    models = compile_srgan_model(g_network=generator_network(), d_network=discriminator_network())\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    g_weight0 = K.eval(models['generator_model'].weights[0][0,0,0,0])\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    _, _ = train_generator(models=models, generator_inputs=generator_inputs, groundtruth_images=groundtruth_images)\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    g_weight1 = K.eval(models['generator_model'].weights[0][0,0,0,0])\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    g_weight0 != g_weight1  #check that generator training has occurred (i.e. weights changed)\n",
      "Expecting:\n",
      "    True\n",
      "ok\n",
      "1 items had no tests:\n",
      "    srgan_train\n",
      "6 items passed all tests:\n",
      "   6 tests in srgan_train.compile_srgan_model\n",
      "   3 tests in srgan_train.discriminator_network\n",
      "   3 tests in srgan_train.generator_network\n",
      "   1 tests in srgan_train.psnr\n",
      "   7 tests in srgan_train.train_discriminator\n",
      "   7 tests in srgan_train.train_generator\n",
      "27 tests in 7 items.\n",
      "27 passed and 0 failed.\n",
      "Test passed.\n"
     ]
    }
   ],
   "source": [
    "_doctest_ipynb('srgan_train.ipynb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepbedmap",
   "language": "python",
   "name": "deepbedmap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
